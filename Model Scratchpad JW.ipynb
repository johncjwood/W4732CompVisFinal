{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package installs\n",
    "#E:\\Python310\\python.exe -m pip install --upgrade pip\n",
    "#!E:\\Python310\\python.exe -m pip install git+https://github.com/openai/whisper.git soundfile\n",
    "#!E:\\Python310\\Scripts\\pip3.exe install ffmpeg av\n",
    "#!E:\\Python310\\python.exe -m pip uninstall torch torchvision torchaudio -y\n",
    "#!E:\\Python310\\python.exe -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV_HOSTNAME:JWGamingPC\n",
      "ENV_FOLDER_DATA:E:\\W4732 Computer Vision\\Final Paper Data\\\n",
      "ENV_PRATT:\n"
     ]
    }
   ],
   "source": [
    "#Global variables\n",
    "import socket\n",
    "import os\n",
    "ENV_HOSTNAME = socket.gethostname()\n",
    "print('ENV_HOSTNAME:' + ENV_HOSTNAME)\n",
    "\n",
    "#store defaults for Jacob here:\n",
    "ENV_FOLDER_DATA = 'C:\\\\Users\\\\jakes\\\\Documents\\\\COMS 4732 - Computer Vision\\\\W4732CompVisFinal\\\\Data\\\\'\n",
    "ENV_FOLDER_DATA_PROC = 'C:\\\\Users\\\\jakes\\\\Documents\\\\COMS 4732 - Computer Vision\\\\W4732CompVisFinal\\\\Data_Proc\\\\'\n",
    "ENV_PRATT = ''\n",
    "\n",
    "\n",
    "if ENV_HOSTNAME == 'JWGamingPC':\n",
    "    ENV_FOLDER_DATA = 'E:\\\\W4732 Computer Vision\\\\Final Paper Data\\\\'\n",
    "    ENV_FOLDER_DATA_PROC = 'E:\\\\W4732 Computer Vision\\\\Final Paper Data Proc\\\\'\n",
    "    ENV_PRATT = ''\n",
    "\n",
    "print('ENV_FOLDER_DATA:' + ENV_FOLDER_DATA)\n",
    "print('ENV_PRATT:' + ENV_PRATT)\n",
    "\n",
    "# Create folder structure\n",
    "import os\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'segmentation', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'targetdf', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'pratt', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'eps', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'clips', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JWVideoConvNet(\n",
       "  (lin1): Linear(in_features=271557, out_features=4096, bias=True)\n",
       "  (lin2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (lin3): Linear(in_features=1024, out_features=41, bias=True)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (maxpool): MaxPool3d(kernel_size=10, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create model result\n",
    "#PATH_MODEL = ENV_FOLDER_DATA_PROC + 'charts\\\\' + 'pitchVidNetV3.pt'\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#torch.save(a.state_dict(), ENV_FOLDER_DATA_PROC + 'charts\\\\' + \"JWPitchModv04Fin.pt\")\n",
    "class JWVideoConvNetV4Fin(torch.nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=41):\n",
    "        super().__init__()\n",
    "        # TODO: Initialize network layers\n",
    "        \n",
    "        \n",
    "        self.conv1 = torch.nn.Conv3d(in_channels=in_channels, out_channels=4, kernel_size=15, padding=3, stride=5)\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(26460, 4096)\n",
    "        self.lin2 = torch.nn.Linear(4096, 1024)\n",
    "        self.lin3 = torch.nn.Linear(1024, num_classes)\n",
    "\n",
    "        self.drop = torch.nn.Dropout(0.1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.maxpool = torch.nn.MaxPool3d(kernel_size=4, stride=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass with using the layers defined above\n",
    "        #       and the proper activation functions\n",
    "        #print(\"input: \", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.lin1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.drop(x)\n",
    "\n",
    "        x = self.lin2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin3(x)\n",
    "        #print(\"fc3: \", x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class JWVideoConvNet(torch.nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=41):\n",
    "        super().__init__()\n",
    "        # TODO: Initialize network layers\n",
    "        \n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(271557, 4096,bias=False)\n",
    "        self.lin2 = torch.nn.Linear(4096, 1024,bias=False)\n",
    "        self.lin3 = torch.nn.Linear(1024, num_classes,bias=False)\n",
    "\n",
    "        self.drop = torch.nn.Dropout(0.1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.maxpool = torch.nn.MaxPool3d(kernel_size=10, stride=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass with using the layers defined above\n",
    "        #       and the proper activation functions\n",
    "        #print(\"input: \", x.shape)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.lin1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.drop(x)\n",
    "\n",
    "        x = self.lin2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin3(x)\n",
    "        #print(\"fc3: \", x.shape)\n",
    "        return x\n",
    "\n",
    "a = JWVideoConvNet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#a.load_state_dict(torch.load(ENV_FOLDER_DATA_PROC + 'charts\\\\' + 'JWPitchModv01.pt'))\n",
    "a.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Epoch=1 Loss=44.614\n",
      "Epoch=1 Loss=75.703\n",
      "Epoch=1 Loss=106.711\n",
      "Epoch=1 Loss=141.172\n",
      "Epoch=1 Loss=164.622\n",
      "Epoch=1 Loss=198.704\n",
      "Epoch=1 Loss=231.393\n",
      "Epoch=1 Loss=266.748\n",
      "Epoch=1 Loss=298.775\n",
      "Epoch=1 Loss=354.346\n",
      "Epoch=1 Loss=396.106\n",
      "Epoch=1 Loss=433.491\n",
      "Epoch=1 Loss=464.146\n",
      "Epoch=1 Loss=497.821\n",
      "Epoch=1 Loss=548.629\n",
      "Epoch:1\n",
      "Epoch=2 Loss=33.794\n",
      "Epoch=2 Loss=66.701\n",
      "Epoch=2 Loss=101.108\n",
      "Epoch=2 Loss=129.568\n",
      "Epoch=2 Loss=160.242\n",
      "Epoch=2 Loss=204.532\n",
      "Epoch=2 Loss=252.494\n",
      "Epoch=2 Loss=281.506\n",
      "Epoch=2 Loss=317.388\n",
      "Epoch=2 Loss=355.989\n",
      "Epoch=2 Loss=389.933\n",
      "Epoch=2 Loss=418.175\n",
      "Epoch=2 Loss=438.869\n",
      "Epoch=2 Loss=502.936\n",
      "Epoch=2 Loss=521.826\n",
      "Epoch:2\n",
      "Epoch=3 Loss=24.062\n",
      "Epoch=3 Loss=58.633\n",
      "Epoch=3 Loss=87.570\n",
      "Epoch=3 Loss=135.284\n",
      "Epoch=3 Loss=185.820\n",
      "Epoch=3 Loss=222.009\n",
      "Epoch=3 Loss=285.287\n",
      "Epoch=3 Loss=316.179\n",
      "Epoch=3 Loss=351.149\n",
      "Epoch=3 Loss=382.062\n",
      "Epoch=3 Loss=417.831\n",
      "Epoch=3 Loss=450.903\n",
      "Epoch=3 Loss=477.690\n",
      "Epoch=3 Loss=508.845\n",
      "Epoch=3 Loss=526.407\n",
      "Epoch:3\n",
      "Epoch=4 Loss=30.614\n",
      "Epoch=4 Loss=84.091\n",
      "Epoch=4 Loss=120.969\n",
      "Epoch=4 Loss=154.278\n",
      "Epoch=4 Loss=184.793\n",
      "Epoch=4 Loss=252.449\n",
      "Epoch=4 Loss=291.852\n",
      "Epoch=4 Loss=328.140\n",
      "Epoch=4 Loss=360.357\n",
      "Epoch=4 Loss=393.358\n",
      "Epoch=4 Loss=418.123\n",
      "Epoch=4 Loss=453.242\n",
      "Epoch=4 Loss=484.708\n",
      "Epoch=4 Loss=502.130\n",
      "Epoch=4 Loss=522.521\n",
      "Epoch:4\n",
      "Epoch=5 Loss=26.860\n",
      "Epoch=5 Loss=52.933\n",
      "Epoch=5 Loss=83.060\n",
      "Epoch=5 Loss=123.833\n",
      "Epoch=5 Loss=155.846\n",
      "Epoch=5 Loss=190.100\n",
      "Epoch=5 Loss=231.211\n",
      "Epoch=5 Loss=259.911\n",
      "Epoch=5 Loss=323.455\n",
      "Epoch=5 Loss=353.720\n",
      "Epoch=5 Loss=379.837\n",
      "Epoch=5 Loss=433.111\n",
      "Epoch=5 Loss=465.845\n",
      "Epoch=5 Loss=505.475\n",
      "Epoch=5 Loss=522.801\n",
      "Epoch:5\n",
      "Epoch=6 Loss=47.051\n",
      "Epoch=6 Loss=69.171\n",
      "Epoch=6 Loss=144.230\n",
      "Epoch=6 Loss=184.055\n",
      "Epoch=6 Loss=215.005\n",
      "Epoch=6 Loss=242.901\n",
      "Epoch=6 Loss=271.456\n",
      "Epoch=6 Loss=301.819\n",
      "Epoch=6 Loss=326.899\n",
      "Epoch=6 Loss=359.208\n",
      "Epoch=6 Loss=404.620\n",
      "Epoch=6 Loss=434.143\n",
      "Epoch=6 Loss=463.739\n",
      "Epoch=6 Loss=494.797\n",
      "Epoch=6 Loss=520.728\n",
      "Epoch:6\n",
      "Epoch=7 Loss=54.228\n",
      "Epoch=7 Loss=86.218\n",
      "Epoch=7 Loss=122.780\n",
      "Epoch=7 Loss=142.684\n",
      "Epoch=7 Loss=178.090\n",
      "Epoch=7 Loss=235.211\n",
      "Epoch=7 Loss=267.685\n",
      "Epoch=7 Loss=306.752\n",
      "Epoch=7 Loss=340.894\n",
      "Epoch=7 Loss=388.531\n",
      "Epoch=7 Loss=414.733\n",
      "Epoch=7 Loss=446.141\n",
      "Epoch=7 Loss=474.865\n",
      "Epoch=7 Loss=506.234\n",
      "Epoch=7 Loss=523.620\n",
      "Epoch:7\n",
      "Epoch=8 Loss=41.358\n",
      "Epoch=8 Loss=103.080\n",
      "Epoch=8 Loss=138.453\n",
      "Epoch=8 Loss=167.803\n",
      "Epoch=8 Loss=198.491\n",
      "Epoch=8 Loss=230.476\n",
      "Epoch=8 Loss=277.124\n",
      "Epoch=8 Loss=306.781\n",
      "Epoch=8 Loss=343.975\n",
      "Epoch=8 Loss=379.726\n",
      "Epoch=8 Loss=408.762\n",
      "Epoch=8 Loss=435.010\n",
      "Epoch=8 Loss=463.326\n",
      "Epoch=8 Loss=501.087\n",
      "Epoch=8 Loss=520.945\n",
      "Epoch:8\n",
      "Epoch=9 Loss=40.513\n",
      "Epoch=9 Loss=79.429\n",
      "Epoch=9 Loss=107.697\n",
      "Epoch=9 Loss=155.144\n",
      "Epoch=9 Loss=190.338\n",
      "Epoch=9 Loss=223.046\n",
      "Epoch=9 Loss=261.746\n",
      "Epoch=9 Loss=293.167\n",
      "Epoch=9 Loss=329.349\n",
      "Epoch=9 Loss=364.988\n",
      "Epoch=9 Loss=391.899\n",
      "Epoch=9 Loss=444.047\n",
      "Epoch=9 Loss=474.266\n",
      "Epoch=9 Loss=502.964\n",
      "Epoch=9 Loss=524.353\n",
      "Epoch:9\n",
      "Epoch=10 Loss=24.298\n",
      "Epoch=10 Loss=50.696\n",
      "Epoch=10 Loss=88.722\n",
      "Epoch=10 Loss=124.076\n",
      "Epoch=10 Loss=166.076\n",
      "Epoch=10 Loss=192.977\n",
      "Epoch=10 Loss=259.882\n",
      "Epoch=10 Loss=291.066\n",
      "Epoch=10 Loss=318.359\n",
      "Epoch=10 Loss=356.447\n",
      "Epoch=10 Loss=391.075\n",
      "Epoch=10 Loss=426.634\n",
      "Epoch=10 Loss=446.840\n",
      "Epoch=10 Loss=497.042\n",
      "Epoch=10 Loss=521.549\n",
      "Epoch:10\n",
      "Epoch=11 Loss=35.914\n",
      "Epoch=11 Loss=93.385\n",
      "Epoch=11 Loss=124.557\n",
      "Epoch=11 Loss=150.329\n",
      "Epoch=11 Loss=181.739\n",
      "Epoch=11 Loss=223.179\n",
      "Epoch=11 Loss=252.098\n",
      "Epoch=11 Loss=282.176\n",
      "Epoch=11 Loss=319.389\n",
      "Epoch=11 Loss=338.574\n",
      "Epoch=11 Loss=369.374\n",
      "Epoch=11 Loss=405.761\n",
      "Epoch=11 Loss=454.198\n",
      "Epoch=11 Loss=498.251\n",
      "Epoch=11 Loss=523.601\n",
      "Epoch:11\n",
      "Epoch=12 Loss=27.007\n",
      "Epoch=12 Loss=84.475\n",
      "Epoch=12 Loss=123.667\n",
      "Epoch=12 Loss=152.499\n",
      "Epoch=12 Loss=200.307\n",
      "Epoch=12 Loss=230.998\n",
      "Epoch=12 Loss=255.181\n",
      "Epoch=12 Loss=286.241\n",
      "Epoch=12 Loss=326.835\n",
      "Epoch=12 Loss=355.766\n",
      "Epoch=12 Loss=418.667\n",
      "Epoch=12 Loss=450.146\n",
      "Epoch=12 Loss=483.773\n",
      "Epoch=12 Loss=513.482\n",
      "Epoch=12 Loss=525.283\n",
      "Epoch:12\n",
      "Epoch=13 Loss=29.321\n",
      "Epoch=13 Loss=60.920\n",
      "Epoch=13 Loss=98.947\n",
      "Epoch=13 Loss=129.555\n",
      "Epoch=13 Loss=188.913\n",
      "Epoch=13 Loss=210.953\n",
      "Epoch=13 Loss=262.774\n",
      "Epoch=13 Loss=293.155\n",
      "Epoch=13 Loss=339.928\n",
      "Epoch=13 Loss=372.816\n",
      "Epoch=13 Loss=399.314\n",
      "Epoch=13 Loss=434.202\n",
      "Epoch=13 Loss=467.114\n",
      "Epoch=13 Loss=508.043\n",
      "Epoch=13 Loss=521.775\n",
      "Epoch:13\n",
      "Epoch=14 Loss=31.697\n",
      "Epoch=14 Loss=63.617\n",
      "Epoch=14 Loss=92.848\n",
      "Epoch=14 Loss=128.429\n",
      "Epoch=14 Loss=178.834\n",
      "Epoch=14 Loss=218.087\n",
      "Epoch=14 Loss=254.050\n",
      "Epoch=14 Loss=283.538\n",
      "Epoch=14 Loss=313.428\n",
      "Epoch=14 Loss=341.955\n",
      "Epoch=14 Loss=379.408\n",
      "Epoch=14 Loss=412.161\n",
      "Epoch=14 Loss=459.259\n",
      "Epoch=14 Loss=494.248\n",
      "Epoch=14 Loss=514.869\n",
      "Epoch:14\n",
      "Epoch=15 Loss=24.706\n",
      "Epoch=15 Loss=102.669\n",
      "Epoch=15 Loss=133.855\n",
      "Epoch=15 Loss=161.924\n",
      "Epoch=15 Loss=193.785\n",
      "Epoch=15 Loss=221.705\n",
      "Epoch=15 Loss=248.466\n",
      "Epoch=15 Loss=296.571\n",
      "Epoch=15 Loss=337.634\n",
      "Epoch=15 Loss=364.665\n",
      "Epoch=15 Loss=401.012\n",
      "Epoch=15 Loss=439.468\n",
      "Epoch=15 Loss=466.605\n",
      "Epoch=15 Loss=504.261\n",
      "Epoch=15 Loss=519.454\n",
      "Epoch:15\n",
      "Epoch=16 Loss=33.151\n",
      "Epoch=16 Loss=85.876\n",
      "Epoch=16 Loss=117.312\n",
      "Epoch=16 Loss=149.501\n",
      "Epoch=16 Loss=178.823\n",
      "Epoch=16 Loss=215.445\n",
      "Epoch=16 Loss=247.213\n",
      "Epoch=16 Loss=301.718\n",
      "Epoch=16 Loss=336.091\n",
      "Epoch=16 Loss=364.567\n",
      "Epoch=16 Loss=391.765\n",
      "Epoch=16 Loss=418.383\n",
      "Epoch=16 Loss=447.393\n",
      "Epoch=16 Loss=476.096\n",
      "Epoch=16 Loss=523.411\n",
      "Epoch:16\n",
      "Epoch=17 Loss=36.385\n",
      "Epoch=17 Loss=88.446\n",
      "Epoch=17 Loss=150.391\n",
      "Epoch=17 Loss=189.211\n",
      "Epoch=17 Loss=224.859\n",
      "Epoch=17 Loss=258.158\n",
      "Epoch=17 Loss=282.261\n",
      "Epoch=17 Loss=310.220\n",
      "Epoch=17 Loss=340.777\n",
      "Epoch=17 Loss=382.669\n",
      "Epoch=17 Loss=417.568\n",
      "Epoch=17 Loss=445.031\n",
      "Epoch=17 Loss=482.388\n",
      "Epoch=17 Loss=505.308\n",
      "Epoch=17 Loss=523.349\n",
      "Epoch:17\n",
      "Epoch=18 Loss=61.105\n",
      "Epoch=18 Loss=97.568\n",
      "Epoch=18 Loss=133.473\n",
      "Epoch=18 Loss=157.233\n",
      "Epoch=18 Loss=202.003\n",
      "Epoch=18 Loss=242.239\n",
      "Epoch=18 Loss=282.039\n",
      "Epoch=18 Loss=316.318\n",
      "Epoch=18 Loss=345.799\n",
      "Epoch=18 Loss=374.215\n",
      "Epoch=18 Loss=402.697\n",
      "Epoch=18 Loss=432.919\n",
      "Epoch=18 Loss=465.422\n",
      "Epoch=18 Loss=505.469\n",
      "Epoch=18 Loss=524.973\n",
      "Epoch:18\n",
      "Epoch=19 Loss=34.881\n",
      "Epoch=19 Loss=77.007\n",
      "Epoch=19 Loss=110.385\n",
      "Epoch=19 Loss=143.907\n",
      "Epoch=19 Loss=175.547\n",
      "Epoch=19 Loss=204.611\n",
      "Epoch=19 Loss=234.906\n",
      "Epoch=19 Loss=265.976\n",
      "Epoch=19 Loss=285.568\n",
      "Epoch=19 Loss=363.081\n",
      "Epoch=19 Loss=390.915\n",
      "Epoch=19 Loss=425.378\n",
      "Epoch=19 Loss=456.077\n",
      "Epoch=19 Loss=488.413\n",
      "Epoch=19 Loss=517.300\n",
      "Epoch:19\n",
      "Epoch=20 Loss=28.439\n",
      "Epoch=20 Loss=59.962\n",
      "Epoch=20 Loss=92.891\n",
      "Epoch=20 Loss=125.402\n",
      "Epoch=20 Loss=151.344\n",
      "Epoch=20 Loss=180.392\n",
      "Epoch=20 Loss=206.078\n",
      "Epoch=20 Loss=254.524\n",
      "Epoch=20 Loss=285.138\n",
      "Epoch=20 Loss=317.065\n",
      "Epoch=20 Loss=348.163\n",
      "Epoch=20 Loss=379.287\n",
      "Epoch=20 Loss=452.629\n",
      "Epoch=20 Loss=483.203\n",
      "Epoch=20 Loss=522.955\n",
      "Epoch:20\n",
      "Epoch=21 Loss=37.657\n",
      "Epoch=21 Loss=68.048\n",
      "Epoch=21 Loss=145.659\n",
      "Epoch=21 Loss=175.022\n",
      "Epoch=21 Loss=216.623\n",
      "Epoch=21 Loss=248.051\n",
      "Epoch=21 Loss=291.466\n",
      "Epoch=21 Loss=321.920\n",
      "Epoch=21 Loss=349.326\n",
      "Epoch=21 Loss=375.724\n",
      "Epoch=21 Loss=403.404\n",
      "Epoch=21 Loss=429.965\n",
      "Epoch=21 Loss=476.416\n",
      "Epoch=21 Loss=507.420\n",
      "Epoch=21 Loss=522.213\n",
      "Epoch:21\n",
      "Epoch=22 Loss=30.963\n",
      "Epoch=22 Loss=58.805\n",
      "Epoch=22 Loss=91.268\n",
      "Epoch=22 Loss=145.670\n",
      "Epoch=22 Loss=185.290\n",
      "Epoch=22 Loss=222.018\n",
      "Epoch=22 Loss=240.357\n",
      "Epoch=22 Loss=272.709\n",
      "Epoch=22 Loss=296.694\n",
      "Epoch=22 Loss=324.757\n",
      "Epoch=22 Loss=364.866\n",
      "Epoch=22 Loss=395.929\n",
      "Epoch=22 Loss=430.423\n",
      "Epoch=22 Loss=496.533\n",
      "Epoch=22 Loss=514.814\n",
      "Epoch:22\n",
      "Epoch=23 Loss=33.692\n",
      "Epoch=23 Loss=59.323\n",
      "Epoch=23 Loss=94.417\n",
      "Epoch=23 Loss=114.139\n",
      "Epoch=23 Loss=146.269\n",
      "Epoch=23 Loss=188.906\n",
      "Epoch=23 Loss=214.069\n",
      "Epoch=23 Loss=278.187\n",
      "Epoch=23 Loss=310.327\n",
      "Epoch=23 Loss=348.891\n",
      "Epoch=23 Loss=383.100\n",
      "Epoch=23 Loss=416.066\n",
      "Epoch=23 Loss=475.955\n",
      "Epoch=23 Loss=510.805\n",
      "Epoch=23 Loss=522.542\n",
      "Epoch:23\n",
      "Epoch=24 Loss=26.375\n",
      "Epoch=24 Loss=44.696\n",
      "Epoch=24 Loss=73.602\n",
      "Epoch=24 Loss=125.095\n",
      "Epoch=24 Loss=158.965\n",
      "Epoch=24 Loss=184.818\n",
      "Epoch=24 Loss=223.759\n",
      "Epoch=24 Loss=258.731\n",
      "Epoch=24 Loss=287.403\n",
      "Epoch=24 Loss=318.081\n",
      "Epoch=24 Loss=373.700\n",
      "Epoch=24 Loss=431.808\n",
      "Epoch=24 Loss=469.902\n",
      "Epoch=24 Loss=507.119\n",
      "Epoch=24 Loss=523.285\n",
      "Epoch:24\n",
      "Epoch=25 Loss=37.847\n",
      "Epoch=25 Loss=63.968\n",
      "Epoch=25 Loss=118.304\n",
      "Epoch=25 Loss=145.279\n",
      "Epoch=25 Loss=176.872\n",
      "Epoch=25 Loss=204.614\n",
      "Epoch=25 Loss=235.875\n",
      "Epoch=25 Loss=270.478\n",
      "Epoch=25 Loss=294.905\n",
      "Epoch=25 Loss=354.750\n",
      "Epoch=25 Loss=382.591\n",
      "Epoch=25 Loss=428.006\n",
      "Epoch=25 Loss=468.482\n",
      "Epoch=25 Loss=501.924\n",
      "Epoch=25 Loss=521.094\n",
      "Epoch:25\n",
      "Epoch=26 Loss=27.118\n",
      "Epoch=26 Loss=55.838\n",
      "Epoch=26 Loss=83.924\n",
      "Epoch=26 Loss=110.814\n",
      "Epoch=26 Loss=163.106\n",
      "Epoch=26 Loss=208.473\n",
      "Epoch=26 Loss=235.686\n",
      "Epoch=26 Loss=265.350\n",
      "Epoch=26 Loss=301.412\n",
      "Epoch=26 Loss=334.760\n",
      "Epoch=26 Loss=367.225\n",
      "Epoch=26 Loss=396.424\n",
      "Epoch=26 Loss=429.105\n",
      "Epoch=26 Loss=495.631\n",
      "Epoch=26 Loss=519.405\n",
      "Epoch:26\n",
      "Epoch=27 Loss=30.945\n",
      "Epoch=27 Loss=61.275\n",
      "Epoch=27 Loss=92.055\n",
      "Epoch=27 Loss=115.322\n",
      "Epoch=27 Loss=149.513\n",
      "Epoch=27 Loss=214.529\n",
      "Epoch=27 Loss=250.641\n",
      "Epoch=27 Loss=285.365\n",
      "Epoch=27 Loss=317.679\n",
      "Epoch=27 Loss=358.033\n",
      "Epoch=27 Loss=388.855\n",
      "Epoch=27 Loss=414.312\n",
      "Epoch=27 Loss=438.909\n",
      "Epoch=27 Loss=482.464\n",
      "Epoch=27 Loss=520.067\n",
      "Epoch:27\n",
      "Epoch=28 Loss=35.551\n",
      "Epoch=28 Loss=66.364\n",
      "Epoch=28 Loss=96.865\n",
      "Epoch=28 Loss=120.294\n",
      "Epoch=28 Loss=146.708\n",
      "Epoch=28 Loss=199.092\n",
      "Epoch=28 Loss=234.138\n",
      "Epoch=28 Loss=260.184\n",
      "Epoch=28 Loss=292.470\n",
      "Epoch=28 Loss=346.730\n",
      "Epoch=28 Loss=386.510\n",
      "Epoch=28 Loss=423.283\n",
      "Epoch=28 Loss=460.496\n",
      "Epoch=28 Loss=497.598\n",
      "Epoch=28 Loss=522.425\n",
      "Epoch:28\n",
      "Epoch=29 Loss=33.823\n",
      "Epoch=29 Loss=72.512\n",
      "Epoch=29 Loss=99.303\n",
      "Epoch=29 Loss=130.737\n",
      "Epoch=29 Loss=191.153\n",
      "Epoch=29 Loss=238.663\n",
      "Epoch=29 Loss=272.793\n",
      "Epoch=29 Loss=295.190\n",
      "Epoch=29 Loss=343.768\n",
      "Epoch=29 Loss=363.994\n",
      "Epoch=29 Loss=402.073\n",
      "Epoch=29 Loss=426.715\n",
      "Epoch=29 Loss=458.450\n",
      "Epoch=29 Loss=493.596\n",
      "Epoch=29 Loss=523.565\n",
      "Epoch:29\n",
      "Epoch=30 Loss=29.190\n",
      "Epoch=30 Loss=61.467\n",
      "Epoch=30 Loss=94.880\n",
      "Epoch=30 Loss=126.829\n",
      "Epoch=30 Loss=170.359\n",
      "Epoch=30 Loss=200.521\n",
      "Epoch=30 Loss=237.980\n",
      "Epoch=30 Loss=265.736\n",
      "Epoch=30 Loss=293.324\n",
      "Epoch=30 Loss=330.691\n",
      "Epoch=30 Loss=391.714\n",
      "Epoch=30 Loss=440.044\n",
      "Epoch=30 Loss=473.080\n",
      "Epoch=30 Loss=507.589\n",
      "Epoch=30 Loss=522.626\n",
      "Epoch:30\n",
      "Epoch=31 Loss=34.020\n",
      "Epoch=31 Loss=61.130\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 155\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m TRAINING_TYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    152\u001b[0m     labels \u001b[38;5;241m=\u001b[39m (labels \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m40\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m--> 155\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# zero the parameter gradients\u001b[39;00m\n\u001b[0;32m    157\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Model Training 1 ##\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "import csv\n",
    "import pickle\n",
    "import torchvision\n",
    "import itertools\n",
    "import torch\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "#get number after # but before space afterwards\n",
    "\n",
    "#generate filepaths\n",
    "folderpath_clipinfo = ENV_FOLDER_DATA_PROC + 'clipinfo\\\\'\n",
    "os.makedirs(folderpath_clipinfo, exist_ok=True)\n",
    "folderpath_sourcedf = ENV_FOLDER_DATA_PROC + 'sourcedf\\\\'\n",
    "os.makedirs(folderpath_sourcedf, exist_ok=True)\n",
    "folderpath_targetdf = ENV_FOLDER_DATA_PROC + 'targetdf\\\\'\n",
    "folderpath_pratt = ENV_FOLDER_DATA_PROC + 'pratt\\\\' \n",
    "filepath_speakers = ENV_FOLDER_DATA_PROC + 'speakers.json'\n",
    "\n",
    "## get overlap between sourcedf files and targetdf files\n",
    "list_eps = []\n",
    "\n",
    "#note - source is actually a dict of dict of tensors\n",
    "dict_sourcedf = {}\n",
    "list_sourcedf_eps = []\n",
    "for path_pickle in glob.glob(folderpath_sourcedf + '*.pickle'):\n",
    "    dict_temp = {}\n",
    "    dict_temp['path'] = path_pickle\n",
    "    str_basenm = os.path.basename(path_pickle)\n",
    "    dict_temp['basenm'] = str_basenm\n",
    "    dict_temp['str_epnum'] = str_basenm.split('.')[0]\n",
    "    int_epnum = int(dict_temp['str_epnum'])\n",
    "    dict_temp['int_epnum'] = int_epnum\n",
    "    list_sourcedf_eps.append(int_epnum)\n",
    "    dict_sourcedf[int_epnum] = dict_temp\n",
    "\n",
    "#note - target is actually a df\n",
    "dict_targetdf = {}\n",
    "list_targetdf_eps = []\n",
    "for path_pickle in glob.glob(folderpath_targetdf + '*.pickle'):\n",
    "    dict_temp = {}\n",
    "    dict_temp['path'] = path_pickle\n",
    "    str_basenm = os.path.basename(path_pickle)\n",
    "    dict_temp['basenm'] = str_basenm\n",
    "    dict_temp['str_epnum'] = str_basenm.split('.')[0]\n",
    "    int_epnum = int(dict_temp['str_epnum'])\n",
    "    dict_temp['int_epnum'] = int_epnum\n",
    "    list_targetdf_eps.append(int_epnum)\n",
    "    dict_targetdf[int_epnum] = dict_temp\n",
    "\n",
    "#populate matches\n",
    "for src_ep in list_sourcedf_eps:\n",
    "    if src_ep in list_targetdf_eps:\n",
    "        list_eps.append(src_ep)\n",
    "\n",
    "#40 data elements\n",
    "list_datacols = []\n",
    "list_datacols.append('m')\n",
    "for i in range(40):\n",
    "    list_datacols.append('d' + str(i))\n",
    "\n",
    "#define model pieces\n",
    "NUM_EPOCHS = 100\n",
    "TRAINING_TYPE = 'p'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#transform=torchvision.transforms.Normalize( mean=(255*0.5), std=(255*0.5) )\n",
    "optimizer = torch.optim.Adam(a.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "\n",
    "\n",
    "##Epoch Loop\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print('Epoch:' + str(e))\n",
    "    #make a copy of the episode list to pop out 2 at a time\n",
    "    list_epocheps = copy.deepcopy(list_eps)\n",
    "    random.shuffle(list_epocheps)\n",
    "\n",
    "    list_loss = []\n",
    "\n",
    "    while len(list_epocheps) > 0:\n",
    "        #load two or 3 episodes into memory at a time\n",
    "        list_tempeps = []\n",
    "        for i in range(3):\n",
    "            if len(list_epocheps) > 0:\n",
    "                list_tempeps.append(list_epocheps.pop())\n",
    "        #load pratt files into memory\n",
    "        dict_target = {}\n",
    "        for i,tempeps in enumerate(list_tempeps):\n",
    "            with open(dict_targetdf[tempeps]['path'], 'rb') as file:\n",
    "                dict_target[tempeps] =  pickle.load(file)\n",
    "                    \n",
    "        #load video files into memory\n",
    "        dict_source = {}\n",
    "        for i,tempeps in enumerate(list_tempeps):\n",
    "            with open(dict_sourcedf[tempeps]['path'], 'rb') as file:\n",
    "                dict_temp = pickle.load(file)\n",
    "                dict_source[tempeps] = dict_temp\n",
    "\n",
    "        #create a list of eps / clips and shuffle\n",
    "        listtup_epseg = []\n",
    "        for key,val in dict_source.items():\n",
    "            for key2,val2 in val.items():\n",
    "                tup_epseg = [key,key2]\n",
    "                listtup_epseg.append( tup_epseg)\n",
    "        random.shuffle(listtup_epseg)\n",
    "\n",
    "        #loop for data elements\n",
    "        for tup_epseg in listtup_epseg:\n",
    "            int_epnum = tup_epseg[0]\n",
    "            int_segnum = tup_epseg[1]\n",
    "            #feed values into the predict / loss / optimize cycle\n",
    "            inputs = None\n",
    "            labels = None\n",
    "            if int_epnum not in dict_source.keys():\n",
    "                continue\n",
    "            if int_segnum not in dict_source[int_epnum].keys():\n",
    "                continue\n",
    "            inputs = dict_source[int_epnum][int_segnum]\n",
    "            #pad inputs\n",
    "            for x in range(40 - len(inputs)):\n",
    "                inputs.append( torch.empty((1,360,640), dtype=torch.int8) )\n",
    "            inputs = torch.stack(inputs[:40], 0)\n",
    "            #transform inputs\n",
    "            #print(inputs.size())\n",
    "            #torch.Size([40, 1, 360, 640])\n",
    "            inputs = inputs.to(torch.float).movedim(0,1).unsqueeze(0) / 255.0\n",
    "            #print(inputs.size())\n",
    "            \n",
    "\n",
    "            #check if labels exist\n",
    "            label_df = dict_target[int_epnum].query('seg==' + str(int_segnum) + ' & type==\"' + TRAINING_TYPE + '\"' )\n",
    "            if len(label_df) == 0:\n",
    "                #print('No labels for ep:' + str(int_epnum) + ' seg:' + str(int_segnum))\n",
    "                continue\n",
    "            labels = torch.squeeze(torch.tensor(label_df[list_datacols].fillna(0).values).to(torch.float))\n",
    "            #normalize labels \n",
    "            if TRAINING_TYPE == 'p':\n",
    "                labels = labels / 600.0\n",
    "            elif TRAINING_TYPE == 'i':\n",
    "                labels = labels / 100.0\n",
    "            elif TRAINING_TYPE == 's':\n",
    "                labels = labels / 2\n",
    "            elif TRAINING_TYPE == 'j':\n",
    "                labels = labels\n",
    "            elif TRAINING_TYPE == 'h':\n",
    "                labels = (labels + 40) / 100\n",
    "            \n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = a(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "            list_loss.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        print(f'Epoch={e + 1} Loss={sum(list_loss):.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #define a function that, given a targetdf value, look up the source - if both exists, use the data to train the model\n",
    "\n",
    "#end loop through data\n",
    "#33 minutes per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model down for future use / training\n",
    "torch.save(a.state_dict(), ENV_FOLDER_DATA_PROC + 'charts\\\\' + \"JWPitchModv04Fin.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have some metric to show "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
