{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Environment Setup </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in e:\\python310\\lib\\site-packages (24.0)\n",
      "Requirement already satisfied: moviepy in e:\\python310\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: pydub in e:\\python310\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: SpeechRecognition in e:\\python310\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: pyAudioAnalysis in e:\\python310\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: speechbrain in e:\\python310\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: pyannote.audio in e:\\python310\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: praat-parselmouth in e:\\python310\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in e:\\python310\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in e:\\python310\\lib\\site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in e:\\python310\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in e:\\python310\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in e:\\python310\\lib\\site-packages (from moviepy) (1.24.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in e:\\python310\\lib\\site-packages (from moviepy) (2.34.0)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in e:\\python310\\lib\\site-packages (from moviepy) (0.4.9)\n",
      "Requirement already satisfied: typing-extensions in e:\\python310\\lib\\site-packages (from SpeechRecognition) (4.10.0)\n",
      "Requirement already satisfied: hyperpyyaml in e:\\python310\\lib\\site-packages (from speechbrain) (1.2.2)\n",
      "Requirement already satisfied: joblib in e:\\python310\\lib\\site-packages (from speechbrain) (1.2.0)\n",
      "Requirement already satisfied: packaging in e:\\python310\\lib\\site-packages (from speechbrain) (23.1)\n",
      "Requirement already satisfied: scipy in e:\\python310\\lib\\site-packages (from speechbrain) (1.8.1)\n",
      "Requirement already satisfied: sentencepiece in e:\\python310\\lib\\site-packages (from speechbrain) (0.2.0)\n",
      "Requirement already satisfied: torch>=1.9 in e:\\python310\\lib\\site-packages (from speechbrain) (2.0.1+cu117)\n",
      "Requirement already satisfied: torchaudio in e:\\python310\\lib\\site-packages (from speechbrain) (2.0.2+cu117)\n",
      "Requirement already satisfied: huggingface-hub in e:\\python310\\lib\\site-packages (from speechbrain) (0.16.4)\n",
      "Requirement already satisfied: asteroid-filterbanks>=0.4 in e:\\python310\\lib\\site-packages (from pyannote.audio) (0.4.0)\n",
      "Requirement already satisfied: einops>=0.6.0 in e:\\python310\\lib\\site-packages (from pyannote.audio) (0.7.0)\n",
      "Requirement already satisfied: lightning>=2.0.1 in e:\\python310\\lib\\site-packages (from pyannote.audio) (2.0.3)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.1 in e:\\python310\\lib\\site-packages (from pyannote.audio) (2.3.0)\n",
      "Requirement already satisfied: pyannote.core>=5.0.0 in e:\\python310\\lib\\site-packages (from pyannote.audio) (5.0.0)\n",
      "Requirement already satisfied: pyannote.database>=5.0.1 in e:\\python310\\lib\\site-packages (from pyannote.audio) (5.0.1)\n",
      "Requirement already satisfied: pyannote.metrics>=3.2 in e:\\python310\\lib\\site-packages (from pyannote.audio) (3.2.1)\n",
      "Requirement already satisfied: pyannote.pipeline>=3.0.1 in e:\\python310\\lib\\site-packages (from pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in e:\\python310\\lib\\site-packages (from pyannote.audio) (2.4.1)\n",
      "Requirement already satisfied: rich>=12.0.0 in e:\\python310\\lib\\site-packages (from pyannote.audio) (13.4.2)\n",
      "Requirement already satisfied: semver>=3.0.0 in e:\\python310\\lib\\site-packages (from pyannote.audio) (3.0.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in e:\\python310\\lib\\site-packages (from pyannote.audio) (0.12.1)\n",
      "Requirement already satisfied: tensorboardX>=2.6 in e:\\python310\\lib\\site-packages (from pyannote.audio) (2.6.2.2)\n",
      "Requirement already satisfied: torch-audiomentations>=0.11.0 in e:\\python310\\lib\\site-packages (from pyannote.audio) (0.11.1)\n",
      "Requirement already satisfied: torchmetrics>=0.11.0 in e:\\python310\\lib\\site-packages (from pyannote.audio) (0.11.4)\n",
      "Requirement already satisfied: filelock in e:\\python310\\lib\\site-packages (from huggingface-hub->speechbrain) (3.9.0)\n",
      "Requirement already satisfied: fsspec in e:\\python310\\lib\\site-packages (from huggingface-hub->speechbrain) (2023.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in e:\\python310\\lib\\site-packages (from huggingface-hub->speechbrain) (6.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in e:\\python310\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (9.3.0)\n",
      "Requirement already satisfied: setuptools in e:\\python310\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (65.5.0)\n",
      "Requirement already satisfied: Jinja2<5.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (3.1.2)\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (1.2.3)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (4.12.2)\n",
      "Requirement already satisfied: click<10.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (8.1.3)\n",
      "Requirement already satisfied: croniter<1.4.0,>=1.3.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (1.3.15)\n",
      "Requirement already satisfied: dateutils<2.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (0.6.12)\n",
      "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (6.3.0)\n",
      "Requirement already satisfied: fastapi<0.89.0,>=0.69.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (0.88.0)\n",
      "Requirement already satisfied: inquirer<5.0,>=2.10.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (3.1.3)\n",
      "Requirement already satisfied: lightning-cloud>=0.5.34 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (0.5.36)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (0.8.0)\n",
      "Requirement already satisfied: psutil<7.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (5.9.5)\n",
      "Requirement already satisfied: pydantic<4.0,>=1.7.4 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (1.10.9)\n",
      "Requirement already satisfied: python-multipart<2.0,>=0.0.5 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (0.0.6)\n",
      "Requirement already satisfied: starlette in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (0.22.0)\n",
      "Requirement already satisfied: starsessions<2.0,>=1.2.1 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (5.9.0)\n",
      "Requirement already satisfied: urllib3<3.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (1.26.13)\n",
      "Requirement already satisfied: uvicorn<2.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (0.22.0)\n",
      "Requirement already satisfied: websocket-client<3.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (1.5.3)\n",
      "Requirement already satisfied: websockets<12.0 in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (11.0.3)\n",
      "Requirement already satisfied: pytorch-lightning in e:\\python310\\lib\\site-packages (from lightning>=2.0.1->pyannote.audio) (2.0.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in e:\\python310\\lib\\site-packages (from omegaconf<3.0,>=2.1->pyannote.audio) (4.9.3)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.4 in e:\\python310\\lib\\site-packages (from pyannote.core>=5.0.0->pyannote.audio) (2.4.0)\n",
      "Requirement already satisfied: pandas>=0.19 in e:\\python310\\lib\\site-packages (from pyannote.database>=5.0.1->pyannote.audio) (2.0.2)\n",
      "Requirement already satisfied: typer>=0.2.1 in e:\\python310\\lib\\site-packages (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio) (0.11.0)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in e:\\python310\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.2.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in e:\\python310\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.6.2)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in e:\\python310\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (0.9.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in e:\\python310\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (3.7.1)\n",
      "Requirement already satisfied: sympy>=1.1 in e:\\python310\\lib\\site-packages (from pyannote.metrics>=3.2->pyannote.audio) (1.11.1)\n",
      "Requirement already satisfied: optuna>=3.1 in e:\\python310\\lib\\site-packages (from pyannote.pipeline>=3.0.1->pyannote.audio) (3.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\python310\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python310\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python310\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\python310\\lib\\site-packages (from rich>=12.0.0->pyannote.audio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\python310\\lib\\site-packages (from rich>=12.0.0->pyannote.audio) (2.15.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\johnc\\appdata\\roaming\\python\\python310\\site-packages (from soundfile>=0.12.1->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in e:\\python310\\lib\\site-packages (from tensorboardX>=2.6->pyannote.audio) (5.26.0)\n",
      "Requirement already satisfied: networkx in e:\\python310\\lib\\site-packages (from torch>=1.9->speechbrain) (3.0)\n",
      "Requirement already satisfied: julius<0.3,>=0.2.3 in e:\\python310\\lib\\site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.2.7)\n",
      "Requirement already satisfied: librosa>=0.6.0 in e:\\python310\\lib\\site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (0.10.1)\n",
      "Requirement already satisfied: torch-pitch-shift>=1.2.2 in e:\\python310\\lib\\site-packages (from torch-audiomentations>=0.11.0->pyannote.audio) (1.2.4)\n",
      "Requirement already satisfied: colorama in e:\\python310\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in e:\\python310\\lib\\site-packages (from hyperpyyaml->speechbrain) (0.18.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in e:\\python310\\lib\\site-packages (from arrow<3.0,>=1.2.0->lightning>=2.0.1->pyannote.audio) (2.8.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\python310\\lib\\site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning>=2.0.1->pyannote.audio) (2.4.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\johnc\\appdata\\roaming\\python\\python310\\site-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio) (2.21)\n",
      "Requirement already satisfied: pytz in e:\\python310\\lib\\site-packages (from dateutils<2.0->lightning>=2.0.1->pyannote.audio) (2023.3)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in e:\\python310\\lib\\site-packages (from deepdiff<8.0,>=5.7.0->lightning>=2.0.1->pyannote.audio) (4.1.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in e:\\python310\\lib\\site-packages (from starlette->lightning>=2.0.1->pyannote.audio) (3.7.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in e:\\python310\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning>=2.0.1->pyannote.audio) (3.8.4)\n",
      "Requirement already satisfied: blessed>=1.19.0 in e:\\python310\\lib\\site-packages (from inquirer<5.0,>=2.10.0->lightning>=2.0.1->pyannote.audio) (1.20.0)\n",
      "Requirement already satisfied: python-editor>=1.0.4 in e:\\python310\\lib\\site-packages (from inquirer<5.0,>=2.10.0->lightning>=2.0.1->pyannote.audio) (1.0.4)\n",
      "Requirement already satisfied: readchar>=3.0.6 in e:\\python310\\lib\\site-packages (from inquirer<5.0,>=2.10.0->lightning>=2.0.1->pyannote.audio) (4.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python310\\lib\\site-packages (from Jinja2<5.0->lightning>=2.0.1->pyannote.audio) (2.1.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in e:\\python310\\lib\\site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in e:\\python310\\lib\\site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.59.1)\n",
      "Requirement already satisfied: pooch>=1.0 in e:\\python310\\lib\\site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in e:\\python310\\lib\\site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in e:\\python310\\lib\\site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in e:\\python310\\lib\\site-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (1.0.8)\n",
      "Requirement already satisfied: pyjwt in e:\\python310\\lib\\site-packages (from lightning-cloud>=0.5.34->lightning>=2.0.1->pyannote.audio) (2.7.0)\n",
      "Requirement already satisfied: six in e:\\python310\\lib\\site-packages (from lightning-cloud>=0.5.34->lightning>=2.0.1->pyannote.audio) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\python310\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\python310\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\python310\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\python310\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\python310\\lib\\site-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio) (3.0.9)\n",
      "Requirement already satisfied: alembic>=1.5.0 in e:\\python310\\lib\\site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.13.1)\n",
      "Requirement already satisfied: colorlog in e:\\python310\\lib\\site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (6.8.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in e:\\python310\\lib\\site-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (2.0.29)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\python310\\lib\\site-packages (from pandas>=0.19->pyannote.database>=5.0.1->pyannote.audio) (2023.3)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in e:\\python310\\lib\\site-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\python310\\lib\\site-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio) (3.1.0)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in e:\\python310\\lib\\site-packages (from starsessions<2.0,>=1.2.1->lightning>=2.0.1->pyannote.audio) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\python310\\lib\\site-packages (from sympy>=1.1->pyannote.metrics>=3.2->pyannote.audio) (1.2.1)\n",
      "Requirement already satisfied: primePy>=1.3 in e:\\python310\\lib\\site-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio) (1.3)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in e:\\python310\\lib\\site-packages (from typer[all]>=0.2.1->pyannote.database>=5.0.1->pyannote.audio) (1.5.4)\n",
      "Requirement already satisfied: h11>=0.8 in e:\\python310\\lib\\site-packages (from uvicorn<2.0->lightning>=2.0.1->pyannote.audio) (0.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning>=2.0.1->pyannote.audio) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning>=2.0.1->pyannote.audio) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in e:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning>=2.0.1->pyannote.audio) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning>=2.0.1->pyannote.audio) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning>=2.0.1->pyannote.audio) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning>=2.0.1->pyannote.audio) (1.3.1)\n",
      "Requirement already satisfied: Mako in e:\\python310\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (1.3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\python310\\lib\\site-packages (from anyio<5,>=3.4.0->starlette->lightning>=2.0.1->pyannote.audio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in e:\\python310\\lib\\site-packages (from anyio<5,>=3.4.0->starlette->lightning>=2.0.1->pyannote.audio) (1.1.1)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in e:\\python310\\lib\\site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning>=2.0.1->pyannote.audio) (0.2.6)\n",
      "Requirement already satisfied: jinxed>=1.1.0 in e:\\python310\\lib\\site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning>=2.0.1->pyannote.audio) (1.2.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in e:\\python310\\lib\\site-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in e:\\python310\\lib\\site-packages (from pooch>=1.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio) (3.6.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\python310\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio) (3.0.3)\n",
      "Requirement already satisfied: ansicon in e:\\python310\\lib\\site-packages (from jinxed>=1.1.0->blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning>=2.0.1->pyannote.audio) (1.89.0)\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\johnc\\appdata\\local\\temp\\pip-req-build-0giy76fb\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: soundfile in e:\\python310\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: numba in e:\\python310\\lib\\site-packages (from openai-whisper==20231117) (0.59.1)\n",
      "Requirement already satisfied: numpy in e:\\python310\\lib\\site-packages (from openai-whisper==20231117) (1.24.1)\n",
      "Requirement already satisfied: torch in e:\\python310\\lib\\site-packages (from openai-whisper==20231117) (2.0.1+cu117)\n",
      "Requirement already satisfied: tqdm in e:\\python310\\lib\\site-packages (from openai-whisper==20231117) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in e:\\python310\\lib\\site-packages (from openai-whisper==20231117) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in e:\\python310\\lib\\site-packages (from openai-whisper==20231117) (0.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\johnc\\appdata\\roaming\\python\\python310\\site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\johnc\\appdata\\roaming\\python\\python310\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in e:\\python310\\lib\\site-packages (from numba->openai-whisper==20231117) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in e:\\python310\\lib\\site-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in e:\\python310\\lib\\site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: filelock in e:\\python310\\lib\\site-packages (from torch->openai-whisper==20231117) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in e:\\python310\\lib\\site-packages (from torch->openai-whisper==20231117) (4.10.0)\n",
      "Requirement already satisfied: sympy in e:\\python310\\lib\\site-packages (from torch->openai-whisper==20231117) (1.11.1)\n",
      "Requirement already satisfied: networkx in e:\\python310\\lib\\site-packages (from torch->openai-whisper==20231117) (3.0)\n",
      "Requirement already satisfied: jinja2 in e:\\python310\\lib\\site-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
      "Requirement already satisfied: colorama in e:\\python310\\lib\\site-packages (from tqdm->openai-whisper==20231117) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\python310\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python310\\lib\\site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\python310\\lib\\site-packages (from sympy->torch->openai-whisper==20231117) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\johnc\\AppData\\Local\\Temp\\pip-req-build-0giy76fb'\n"
     ]
    }
   ],
   "source": [
    "#package installs\n",
    "!E:\\Python310\\python.exe -m pip install --upgrade pip\n",
    "!E:\\Python310\\Scripts\\pip3.exe install moviepy pydub SpeechRecognition pyAudioAnalysis speechbrain pyannote.audio praat-parselmouth\n",
    "!E:\\Python310\\python.exe -m pip install git+https://github.com/openai/whisper.git soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#norms for data storage and manipulation\n",
    "\n",
    "#ENV_FOLDER_DATA = source mp4 folder -> this is where the mp4s might be downloaded\n",
    "## This should be separate so we can iterate through this easily\n",
    "#ENV_FOLDER_DATA_PROC = where folders w/ processed + temp data will live\n",
    "\n",
    "## raw per-episode data storage\n",
    "#ENV_FOLDER_DATA_PROC\\\\eps\\\\#### = 3-4 digit numbered folder which represents the episode number\n",
    "#ENV_FOLDER_DATA_PROC\\\\eps\\\\####\\\\####.mp3 = saved mp3\n",
    "#ENV_FOLDER_DATA_PROC\\\\eps\\\\####\\\\####.wav = saved wav file\n",
    "#ENV_FOLDER_DATA_PROC\\\\eps\\\\####\\\\wavsplit\\\\ = folders w/ split wav files\n",
    "#ENV_FOLDER_DATA_PROC\\\\eps\\\\####\\\\wavsplit\\\\segment#-speaker#.wav = split wav file\n",
    "\n",
    "## shared outputs from process\n",
    "#ENV_FOLDER_DATA_PROC\\\\pickle\\\\####.pickle = saved metadata about the files, processing, locations, etc. all stored as a dictionary in a pickle\n",
    "#ENV_FOLDER_DATA_PROC\\\\segmentation\\\\####.txt = saved speaker segmentation from diarization\n",
    "#ENV_FOLDER_DATA_PROC\\\\speakers.json = json which identifies Joe Rogan vs Other Speaker\n",
    "## 568|SPEAKER 0|Joe Rogan\n",
    "## 568|SPEAKER 1|Rhonda Patrick\n",
    "#ENV_FOLDER_DATA_PROC\\\\targetclips\\\\####.txt = chosen clips for use in analysis\n",
    "## 10\n",
    "## 11\n",
    "## 12\n",
    "#ENV_FOLDER_DATA_PROC\\\\pratt\\\\####-segment#-speaker#.pickle = saved pratt data in dictionaries with the 4 time series outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV_HOSTNAME:JWGamingPC\n",
      "ENV_FOLDER_DATA:E:\\W4732 Computer Vision\\Final Paper Data\\\n",
      "ENV_PRATT:\n"
     ]
    }
   ],
   "source": [
    "#Global variables\n",
    "import socket\n",
    "import os\n",
    "ENV_HOSTNAME = socket.gethostname()\n",
    "print('ENV_HOSTNAME:' + ENV_HOSTNAME)\n",
    "\n",
    "#store defaults for Jacob here:\n",
    "ENV_FOLDER_DATA = ''\n",
    "ENV_FOLDER_DATA_PROC = ''\n",
    "ENV_PRATT = ''\n",
    "\n",
    "\n",
    "if ENV_HOSTNAME == 'JWGamingPC':\n",
    "    ENV_FOLDER_DATA = 'E:\\\\W4732 Computer Vision\\\\Final Paper Data\\\\'\n",
    "    ENV_FOLDER_DATA_PROC = 'E:\\\\W4732 Computer Vision\\\\Final Paper Data Proc\\\\'\n",
    "    ENV_PRATT = ''\n",
    "\n",
    "print('ENV_FOLDER_DATA:' + ENV_FOLDER_DATA)\n",
    "print('ENV_PRATT:' + ENV_PRATT)\n",
    "\n",
    "# Create folder structure\n",
    "import os\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'segmentation', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'targetdf', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'pratt', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'eps', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Functions </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Audio Processing 1 ##\n",
    "# Code to generate mp3s, wavs, and segmentation\n",
    "# Norm - save all filepaths as \"suffixes\" aka filesuf and always concatenate the ENV_FOLDER_DATA or the ENV_FOLDER_DATA_PROC\n",
    "\n",
    "#Utility Function\n",
    "## 1) Store all the metadata et al from the functions into a dictionary, which then gets saved to a blob\n",
    "## 2) Save and load blob\n",
    "## 3) Figure out names of relevant files and relevant folder structure\n",
    "## 4) Download episodes from archive.org\n",
    "\n",
    "#Audio Functions\n",
    "## 1) Split MP4 to MP3\n",
    "## 2) MP3 to WAV\n",
    "## 3) WAV to speaker identification and time splits + record file\n",
    "## 4) WAV splits into individual files\n",
    "## 5) Figure out which segments to analyze w/ video (skip first and last segment from the speaker)\n",
    "## 6) Take first second of the segment and produce Pratt time series (0.1 second intervals)\n",
    "## 6a+b+c+d) Pitch + Intensity + Harmonics + Jitter \n",
    "\n",
    "#Library imports\n",
    "import moviepy\n",
    "import moviepy.editor\n",
    "from pydub import AudioSegment\n",
    "from pyannote.audio import Pipeline\n",
    "import csv\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "#extract audio into mp3\n",
    "#https://medium.com/featurepreneur/extracting-audio-from-video-using-pythons-moviepy-library-e351cd652ab8\n",
    "\n",
    "def split_mp4_to_mp3(filepath_mp4 , filepath_mp3):\n",
    "    # Load the video clip\n",
    "    video_clip = moviepy.editor.VideoFileClip(filepath_mp4)\n",
    "\n",
    "    # Extract the audio from the video clip\n",
    "    audio_clip = video_clip.audio\n",
    "\n",
    "    # Write the audio to a separate file\n",
    "    audio_clip.write_audiofile(filepath_mp3)\n",
    "\n",
    "    # Close the video and audio clips\n",
    "    audio_clip.close()\n",
    "    video_clip.close()\n",
    "\n",
    "def split_mp3_to_wav(filepath_mp3, filepath_wav):\n",
    "    #read mp3\n",
    "    mp3_clip = AudioSegment.from_mp3(filepath_mp3)\n",
    "    mp3_clip.export(filepath_wav, format=\"wav\")\n",
    "    del mp3_clip\n",
    "\n",
    "def speaker_diarization(filepath_wav,filepath_segmentation):\n",
    "    #perform speaker diarization (lingo for \"speaker recognition\")\n",
    "    #https://medium.com/@gil.shomron/whos-talking-speaker-diarization-and-emotion-recognition-in-radio-3e9623baeb2c\n",
    "\n",
    "    pipeline = Pipeline.from_pretrained('pyannote/speaker-diarization-3.1',\n",
    "                                        use_auth_token='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')\n",
    "    \n",
    "    pipeline.to(torch.device(\"cuda\"))\n",
    "    diarization = pipeline(filepath_wav)\n",
    "    #for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    #  print('start={.1f} stop={.1f} speaker_{}'.format(turn.start,\n",
    "    #                                                   turn.end,\n",
    "    #                                                   speaker))    \n",
    "\n",
    "    # Dump to file in an RTTM format\n",
    "    #with open(ENV_FOLDER_DATA_PROC + '568\\\\segment.txt', 'w') as rttm:\n",
    "    #    diarization.write_rttm(rttm)\n",
    "    list_diarization_data = []\n",
    "    i = 0\n",
    "    for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "        list_temp = []\n",
    "        list_temp.append(str(i))\n",
    "        list_temp.append(str(speaker))\n",
    "        list_temp.append(str(turn.start))\n",
    "        list_temp.append(str(turn.end))\n",
    "        list_diarization_data.append(list_temp)\n",
    "        i += 1\n",
    "    with open(filepath_segmentation, \"w\", newline='\\n') as f:\n",
    "        writer = csv.writer(f, delimiter='|',  quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerows(list_diarization_data)\n",
    "    #took 81 minutes\n",
    "\n",
    "def wav_file_splitting(filepath_wav, filepath_segmentation,folderpath_wavsplit):\n",
    "    #use cutoffs to split wav file into sections\n",
    "    #https://stackoverflow.com/questions/51622865/break-up-a-wav-file-by-timestamp\n",
    "\n",
    "    listdict_data = []\n",
    "    #read csv file\n",
    "    with open(filepath_segmentation, newline='\\n') as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter='|')\n",
    "        for row in reader:\n",
    "            dict_temp = {}\n",
    "            dict_temp['str_segment'] = row[0]\n",
    "            dict_temp['speaker'] = row[1]\n",
    "            dict_temp['sec_start'] = row[2]\n",
    "            dict_temp['sec_end'] = row[3]\n",
    "            listdict_data.append(dict_temp)\n",
    "    \n",
    "    #split \n",
    "    audio = AudioSegment.from_wav(filepath_wav)\n",
    "    for  idx,dict_data in enumerate(listdict_data):\n",
    "        start = int(float(dict_data['sec_start'])*1000)  #pydub works in millisec\n",
    "        end = int(float(dict_data['sec_end']) * 1000) #pydub works in millisec\n",
    "        audio_chunk=audio[start:end]\n",
    "        audio_chunk.export( folderpath_wavsplit + dict_data['str_segment'] + '-' + dict_data['speaker'] + \".wav\", format=\"wav\")\n",
    "\n",
    "\n",
    "def process_mp4s_for_processing(filesuf_mp4, recalc = False):\n",
    "    #get number after # but before space afterwards\n",
    "    str_epnum_temp = filesuf_mp4.split('#')[1]\n",
    "    str_epnum = str_epnum_temp.split(' ')[0]\n",
    "    \n",
    "    #generate filepaths\n",
    "    filepath_mp4 = ENV_FOLDER_DATA + filesuf_mp4\n",
    "    print('Episode='+ str_epnum + ' at ' + filepath_mp4)\n",
    "    folderpath_eps = ENV_FOLDER_DATA_PROC + 'eps\\\\' + str_epnum + '\\\\'\n",
    "    os.makedirs(folderpath_eps, exist_ok=True)\n",
    "    filepath_mp3 = folderpath_eps + str_epnum + '.mp3'\n",
    "    filepath_wav = folderpath_eps + str_epnum + '.wav'\n",
    "    folderpath_wavsplit = folderpath_eps + 'wavsplit\\\\'\n",
    "    os.makedirs(folderpath_wavsplit, exist_ok=True)\n",
    "    #filepath_pickle = ENV_FOLDER_DATA_PROC + 'pickle\\\\' + str_epnum + '.pickle'\n",
    "    filepath_segmentation = ENV_FOLDER_DATA_PROC + 'segmentation\\\\' + str_epnum + '.psv'\n",
    "    #filepath_targetdf = ENV_FOLDER_DATA_PROC + 'targetdf\\\\' + str_epnum + '.pickle'\n",
    "    #filepath_pratt = ENV_FOLDER_DATA_PROC + 'pratt\\\\' + str_epnum + '.pickle'\n",
    "\n",
    "    #check if mp3 exists - if it doesn't, create it\n",
    "    if not os.path.exists(filepath_mp3):\n",
    "        split_mp4_to_mp3(filepath_mp4,filepath_mp3)\n",
    "    if not os.path.exists(filepath_mp3):\n",
    "        print('Failed to create MP3:'+ filepath_mp3)\n",
    "        return -1\n",
    "    #check if wav exists - if it doesn't, create it\n",
    "    if not os.path.exists(filepath_wav):\n",
    "        split_mp3_to_wav(filepath_mp3,filepath_wav)\n",
    "    #fail if process fails to produce the expected output\n",
    "    if not os.path.exists(filepath_wav):\n",
    "        print('Failed to create WAV:'+ filepath_wav)\n",
    "        return -1\n",
    "    \n",
    "    #check if segmentation exists - if it doesn't, create it\n",
    "    if not os.path.exists(filepath_segmentation):\n",
    "        speaker_diarization(filepath_wav,filepath_segmentation)\n",
    "    else:\n",
    "        print(\"Speaker diarization exists:\" + filepath_segmentation)\n",
    "    #fail if process fails to produce the expected output\n",
    "    if not os.path.exists(filepath_segmentation):\n",
    "        print('Failed to create segmentation:'+ filepath_segmentation)\n",
    "        return -1\n",
    "    \n",
    "    #check if split wav files exist - if it doesn't, create it\n",
    "    if len(glob.glob(folderpath_wavsplit + '*')) < 10:\n",
    "        wav_file_splitting(filepath_wav, filepath_segmentation,folderpath_wavsplit)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Audio Processing 2 ##\n",
    "# Code to generate target clips, pratt pickles\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "from pydub import AudioSegment\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "#AudioSegment.converter = \"C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\ffmpeg-full\\\\tools\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "#AudioSegment.ffmpeg = \"C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\ffmpeg-full\\\\tools\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "#AudioSegment.ffprobe =\"C:\\\\ProgramData\\\\chocolatey\\\\lib\\\\ffmpeg-full\\\\tools\\\\ffmpeg\\\\bin\\\\ffprobe.exe\"\n",
    "\n",
    "def process_mp4s_for_analysis(filesuf_mp4, recalc = False):\n",
    "    #get number after # but before space afterwards\n",
    "    str_epnum_temp = filesuf_mp4.split('#')[1]\n",
    "    str_epnum = str_epnum_temp.split(' ')[0]\n",
    "    \n",
    "    #generate filepaths\n",
    "    filepath_mp4 = ENV_FOLDER_DATA + filesuf_mp4\n",
    "    print('Episode='+ str_epnum + ' at ' + filepath_mp4)\n",
    "    folderpath_eps = ENV_FOLDER_DATA_PROC + 'eps\\\\' + str_epnum + '\\\\'\n",
    "    os.makedirs(folderpath_eps, exist_ok=True)\n",
    "    filepath_mp3 = folderpath_eps + str_epnum + '.mp3'\n",
    "    filepath_wav = folderpath_eps + str_epnum + '.wav'\n",
    "    folderpath_wavsplit = folderpath_eps + 'wavsplit\\\\'\n",
    "    os.makedirs(folderpath_wavsplit, exist_ok=True)\n",
    "    filepath_segmentation = ENV_FOLDER_DATA_PROC + 'segmentation\\\\' + str_epnum + '.psv'\n",
    "    #filepath_targetdf = ENV_FOLDER_DATA_PROC + 'targetdf\\\\' + str_epnum + '.pickle'\n",
    "    filepath_pratt = ENV_FOLDER_DATA_PROC + 'pratt\\\\' + str_epnum + '.pickle'\n",
    "\n",
    "    if os.path.exists(filepath_pratt):\n",
    "        print('Pratt data already generated:'+ filepath_pratt)\n",
    "        return 0\n",
    "\n",
    "    dict_speakerdata = {}\n",
    "    for i in range(20):\n",
    "        speaker = 'SPEAKER_' + str(i).zfill(2)\n",
    "        dict_speakerdata[speaker] = {}\n",
    "        dict_speakerdata[speaker]['list_pitch'] = []\n",
    "        dict_speakerdata[speaker]['list_intensity'] = []\n",
    "        dict_speakerdata[speaker]['list_shimmer'] = []\n",
    "        dict_speakerdata[speaker]['list_jitter'] = []\n",
    "        dict_speakerdata[speaker]['list_harmonics'] = []\n",
    "\n",
    "\n",
    "    #get list of wav files to iterate through\n",
    "    dictdict_output = {} #key = filesuf / value = dictionary\n",
    "    for path_wav in glob.glob(folderpath_wavsplit + '*.wav'):\n",
    "        #create data points and save into a dictionary\n",
    "        dict_temp = {}\n",
    "        dict_temp['path'] = path_wav\n",
    "        filesuf = os.path.basename(path_wav)\n",
    "        dict_temp['filesuf'] = filesuf\n",
    "        dict_temp['str_segment'] = filesuf.split('-')[0]\n",
    "        speaker = (filesuf.split('-')[1]).split('.')[0]\n",
    "        dict_temp['speaker'] = speaker\n",
    "        \n",
    "\n",
    "        sound_total = parselmouth.Sound(path_wav)\n",
    "        second_duration = call(sound_total, \"Get total duration\") \n",
    "        tenth_seconds = int(second_duration * 10)\n",
    "        dict_temp['duration'] = second_duration\n",
    "        #create dictionaries for all the values to be stored\n",
    "        list_pitch = []\n",
    "        list_intensity = []\n",
    "        list_shimmer = []\n",
    "        list_jitter = []\n",
    "        list_harmonics = []\n",
    "\n",
    "        for t in range(tenth_seconds):\n",
    "\n",
    "            start_time = t * 0.1\n",
    "            end_time = (t + 1) * 0.1\n",
    "            sound = sound_total.extract_part(from_time=start_time, to_time=end_time)\n",
    "\n",
    "            #iterate through the parts of the sound\n",
    "\n",
    "            pointprocess = call(sound, \"To PointProcess (periodic, cc)\",75, 600)\n",
    "            #dict_temp['pointprocess'] = pointprocess\n",
    "            \n",
    "            #https://parselmouth.readthedocs.io/_/downloads/en/stable/pdf/\n",
    "            #gets the pitch , and sets the pitch floor to 75 and tge outcg max to 600\n",
    "            try:\n",
    "                pitch = call(sound, \"To Pitch\", 0.0, 75, 600)\n",
    "                val_pitch = call(pitch, \"Get mean\", 0, 0,\"Hertz\")\n",
    "            except:\n",
    "                val_pitch = None\n",
    "            \n",
    "            ##-\tFor intensity extraction, set the pitch floor to 100Hz. Use ‘energy’ averaging method to get mean intensity.\n",
    "            try:\n",
    "                intensity = call(sound, \"To Intensity\", 100,0.01)\n",
    "                val_intensity = call(intensity, \"Get mean\", 0, 0,\"energy\")\n",
    "            except:\n",
    "                val_intensity = None\n",
    "\n",
    "            ##Shimmer\n",
    "            # For shimmer, extract local shimmer only, and set period floor to 0.0001s, period ceiling to 0.02s, maximum period factor to 1.3, and maximum amplitude factor to 1.6.\n",
    "            try:\n",
    "                val_shimmer = call([sound, pointprocess], \"Get shimmer (local)\", 0, 0, 0.0001, 0.02, 1.3, 1.6)\n",
    "            except:\n",
    "                val_shimmer = None\n",
    "            \n",
    "            # For jitter, extract local jitter only, and set period floor to 0.0001s, period ceiling to 0.02s, and maximum period factor to 1.3\n",
    "            #Please convert from a Sound object to a PointProcess (periodic, cc) object. (#74)\n",
    "            #https://github.com/drfeinberg/PraatScripts/blob/master/Measure%20Pitch%2C%20HNR%2C%20Jitter%2C%20Shimmer%2C%20and%20Formants.ipynb\n",
    "            #f0min , f0max\n",
    "            try:\n",
    "                val_jitter = call(pointprocess, \"Get jitter (local)\", 0, 0, 0.0001, 0.02, 1.3)\n",
    "            except:\n",
    "                val_jitter = None\n",
    "            \n",
    "            #-\tTo calculate HNR (harmonics-to-noise ratio), extract harmonicity (cc) first. Set time step to 0.01, minimum pitch to 75Hz, silence threshold to 0.1, and number of periods per window to 1.0.\n",
    "            try:\n",
    "                harmonics = call(sound, \"To Harmonicity (cc)\", 0.01, 75, 0.1, 1.0)\n",
    "                val_harmonics = call(harmonics, \"Get mean\", 0, 0)\n",
    "            except:\n",
    "                val_harmonics = None\n",
    "\n",
    "            #add to relevant lists\n",
    "            list_pitch.append(val_pitch)\n",
    "            list_intensity.append(val_intensity)\n",
    "            list_shimmer.append(val_shimmer)\n",
    "            list_jitter.append(val_jitter)\n",
    "            list_harmonics.append(val_harmonics)\n",
    "\n",
    "            dict_speakerdata[speaker]['list_pitch'].append(val_pitch)\n",
    "            dict_speakerdata[speaker]['list_intensity'].append(val_intensity)\n",
    "            dict_speakerdata[speaker]['list_shimmer'].append(val_shimmer)\n",
    "            dict_speakerdata[speaker]['list_jitter'].append(val_jitter)\n",
    "            dict_speakerdata[speaker]['list_harmonics'].append(val_harmonics)\n",
    "        #end for loop that goes per-0.1 second\n",
    "        dict_temp['list_pitch'] = list_pitch\n",
    "        dict_temp['list_intensity'] = list_intensity\n",
    "        dict_temp['list_shimmer'] = list_shimmer\n",
    "        dict_temp['list_jitter'] = list_jitter\n",
    "        dict_temp['list_harmonics'] = list_harmonics\n",
    "        \n",
    "        dictdict_output[filesuf] = dict_temp\n",
    "    #end for loop that goes through each file in the folder\n",
    "    \n",
    "    #calculate statistics for the speakers\n",
    "    for i in range(20):\n",
    "        speaker = 'SPEAKER_0' + str(i).zfill(2)\n",
    "        dictdict_output[speaker] = {}\n",
    "\n",
    "        dictdict_output[speaker]['mean_pitch'] = np.nanmean(list(filter(None, dict_speakerdata[speaker]['list_pitch']) ))\n",
    "        dictdict_output[speaker]['median_pitch'] = np.nanmedian(list(filter(None,dict_speakerdata[speaker]['list_pitch'])))\n",
    "        dictdict_output[speaker]['mean_intensity'] = np.nanmean(list(filter(None,dict_speakerdata[speaker]['list_intensity'])))\n",
    "        dictdict_output[speaker]['median_intensity'] = np.nanmedian(list(filter(None,dict_speakerdata[speaker]['list_intensity'])))\n",
    "        dictdict_output[speaker]['mean_shimmer'] = np.nanmean(list(filter(None,dict_speakerdata[speaker]['list_shimmer'])))\n",
    "        dictdict_output[speaker]['median_shimmer'] = np.nanmedian(list(filter(None,dict_speakerdata[speaker]['list_shimmer'])))\n",
    "        dictdict_output[speaker]['mean_jitter'] = np.nanmean(list(filter(None,dict_speakerdata[speaker]['list_jitter'])))\n",
    "        dictdict_output[speaker]['median_jitter'] = np.nanmedian(list(filter(None,dict_speakerdata[speaker]['list_jitter'])))\n",
    "        dictdict_output[speaker]['mean_harmonics'] = np.nanmean(list(filter(None,dict_speakerdata[speaker]['list_harmonics'])))\n",
    "        dictdict_output[speaker]['median_harmonics'] = np.nanmedian(list(filter(None,dict_speakerdata[speaker]['list_harmonics'])))\n",
    "\n",
    "\n",
    "\n",
    "    #save data\n",
    "    with open(filepath_pratt, 'wb') as file:\n",
    "        print(filepath_pratt)\n",
    "        pickle.dump(dictdict_output, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Audio Processing 3 ##\n",
    "# Producing a filtered object to use for training the model\n",
    "# Target output is a dataframe saved into the targetdf folder\n",
    "# data will be filtering out both speaker = Joe Rogan and speaker = Misc so only the guest is included\n",
    "# data will also be filtering out the first instance of talking by that speaker\n",
    "# data will also be filtering out clips < 1 second\n",
    "# Dataframe has the following columns\n",
    "# epnum -> int (episode #)\n",
    "# seg -> int (segment)\n",
    "# type -> p for pitch, i for intensity,  j for fitter , h for harmonics, s for shimmer \n",
    "# m -> global median for that statistic\n",
    "# d0,d1, .... d99 -> values for the first 10 seconds in 0.1 second increments \n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "\n",
    "def process_analysis_for_model(filesuf_mp4, recalc = False):\n",
    "    #get number after # but before space afterwards\n",
    "    str_epnum_temp = filesuf_mp4.split('#')[1]\n",
    "    str_epnum = str_epnum_temp.split(' ')[0]\n",
    "    int_epnum = int(str_epnum)\n",
    "    \n",
    "    #generate filepaths\n",
    "    filepath_mp4 = ENV_FOLDER_DATA + filesuf_mp4\n",
    "    print('Episode='+ str_epnum + ' at ' + filepath_mp4)\n",
    "    folderpath_eps = ENV_FOLDER_DATA_PROC + 'eps\\\\' + str_epnum + '\\\\'\n",
    "    os.makedirs(folderpath_eps, exist_ok=True)\n",
    "    filepath_mp3 = folderpath_eps + str_epnum + '.mp3'\n",
    "    filepath_wav = folderpath_eps + str_epnum + '.wav'\n",
    "    folderpath_wavsplit = folderpath_eps + 'wavsplit\\\\'\n",
    "    os.makedirs(folderpath_wavsplit, exist_ok=True)\n",
    "    filepath_segmentation = ENV_FOLDER_DATA_PROC + 'segmentation\\\\' + str_epnum + '.psv'\n",
    "    filepath_targetdf = ENV_FOLDER_DATA_PROC + 'targetdf\\\\' + str_epnum + '.pickle'\n",
    "    filepath_pratt = ENV_FOLDER_DATA_PROC + 'pratt\\\\' + str_epnum + '.pickle'\n",
    "    filepath_speakers = ENV_FOLDER_DATA_PROC + 'speakers.json'\n",
    "\n",
    "    #open dict of speakers\n",
    "    \n",
    "    json_speakers = {}\n",
    "    with open(filepath_speakers) as f:\n",
    "        json_speakers = json.load(f)\n",
    "    \n",
    "    #determine speakers to retain\n",
    "    list_speakers_keep = []\n",
    "\n",
    "    for key,val in json_speakers[str_epnum].items():\n",
    "        if val == 'Joe Rogan':\n",
    "            continue\n",
    "        if val == 'Misc':\n",
    "            continue\n",
    "        list_speakers_keep.append(key)\n",
    "\n",
    "    #declare default dictionary\n",
    "    dict_default = {}\n",
    "    dict_default['epnum'] = int_epnum\n",
    "    dict_default['seg'] = 0\n",
    "    dict_default['type'] = ''\n",
    "    dict_default['m'] = 0\n",
    "    for i in range(100):\n",
    "        dict_default['d' + str(i)] = 0\n",
    "\n",
    "    #declare empty dataframe with the 44 columns\n",
    "    df = pd.DataFrame( columns= list(dict_default.keys()) )\n",
    "\n",
    "    #open up pratt pickle\n",
    "    dictdict_output = None\n",
    "    with open(filepath_pratt, 'rb') as file:\n",
    "        print(filepath_pratt)\n",
    "        dictdict_output = pickle.load(file)\n",
    "    \n",
    "    #iterate through each segment\n",
    "    for key,val in dictdict_output.items():\n",
    "        #if there's no dash in the key, then the key is one of the aggregate values\n",
    "        if '-' not in key:\n",
    "            continue\n",
    "        filesuf = val['filesuf']\n",
    "        str_segment = val['str_segment']\n",
    "        int_segment = int(str_segment)\n",
    "        speaker = val['speaker']\n",
    "\n",
    "        #skip if it's less than 1 second\n",
    "        if val['duration'] < 1.0:\n",
    "            continue\n",
    "\n",
    "        #skip data if it's Joe Rogan or Misc\n",
    "        if speaker not in list_speakers_keep:\n",
    "            continue\n",
    "\n",
    "        dict_temp = copy.deepcopy(dict_default)\n",
    "        dict_temp['seg'] = int_segment\n",
    "        list_dict = []\n",
    "\n",
    "        #make a new copy for pitch, intensity, shimmer, jitter, harmonics\n",
    "        #pitch\n",
    "        dict_pitch = copy.deepcopy(dict_temp)\n",
    "        dict_pitch['type'] = 'p'\n",
    "        dict_pitch['m'] = dictdict_output[speaker]['median_pitch']\n",
    "        for i, data in enumerate(val['list_pitch']):\n",
    "            dict_pitch['d'+str(i)] = data\n",
    "        list_dict.append(dict_pitch)\n",
    "\n",
    "\n",
    "        #intensity\n",
    "        dict_intensity = copy.deepcopy(dict_temp)\n",
    "        dict_intensity['type'] = 'i'\n",
    "        dict_intensity['m'] = dictdict_output[speaker]['median_intensity']\n",
    "        for i, data in enumerate(val['list_intensity']):\n",
    "            dict_intensity['d'+str(i)] = data\n",
    "        list_dict.append(dict_intensity)\n",
    "\n",
    "\n",
    "        #shimmer\n",
    "        dict_shimmer = copy.deepcopy(dict_temp)\n",
    "        dict_shimmer['type'] = 's'\n",
    "        dict_shimmer['m'] = dictdict_output[speaker]['median_shimmer']\n",
    "        for i, data in enumerate(val['list_shimmer']):\n",
    "            dict_shimmer['d'+str(i)] = data\n",
    "        list_dict.append(dict_shimmer)\n",
    "\n",
    "\n",
    "        #jitter\n",
    "        dict_jitter = copy.deepcopy(dict_temp)\n",
    "        dict_jitter['type'] = 'j'\n",
    "        dict_jitter['m'] = dictdict_output[speaker]['median_jitter']\n",
    "        for i, data in enumerate(val['list_jitter']):\n",
    "            dict_jitter['d'+str(i)] = data\n",
    "        list_dict.append(dict_jitter)\n",
    "\n",
    "\n",
    "        #harmonics\n",
    "        dict_harmonics = copy.deepcopy(dict_temp)\n",
    "        dict_harmonics['type'] = 'h'\n",
    "        dict_harmonics['m'] = dictdict_output[speaker]['median_harmonics']\n",
    "        for i, data in enumerate(val['list_harmonics']):\n",
    "            dict_harmonics['d'+str(i)] = data\n",
    "        list_dict.append(dict_harmonics)\n",
    "\n",
    "        #turn list of dicts into dataframe\n",
    "        df_temp = pd.DataFrame(list_dict, columns=list(dict_default.keys()) )\n",
    "        df = pd.concat([df,df_temp], ignore_index=True)\n",
    "    \n",
    "    #end loop through data\n",
    "    \n",
    "    #save data\n",
    "    with open(filepath_targetdf, 'wb') as file:\n",
    "        pickle.dump(df, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test audio processing\n",
    "# using test video #568 Dr. Rhonda Patrick\n",
    "# https://archive.org/download/jre-001-837/JRE_001-837/\n",
    "# https://archive.org/download/jre-001-837/JRE_001-837/Joe%20Rogan%20Experience%20%23568%20-%20Dr.%20Rhonda%20Patrick.mp4\n",
    "\n",
    "filesuf_mp4 = 'Joe Rogan Experience #568 - Dr. Rhonda Patrick.mp4'\n",
    "#process_mp4s_for_processing(filesuf_mp4)\n",
    "\n",
    "  #speaker 2 is joe rogan\n",
    "  #speaker 0 is the lady\n",
    "  #speaker 1 is the sound effects \n",
    "  #time start and stop is in seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pratt processing\n",
    "filesuf_mp4 = 'Joe Rogan Experience #568 - Dr. Rhonda Patrick.mp4'\n",
    "#process_mp4s_for_analysis(filesuf_mp4, recalc = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataframe output\n",
    "filesuf_mp4 = 'Joe Rogan Experience #568 - Dr. Rhonda Patrick.mp4'\n",
    "#process_analysis_for_model(filesuf_mp4, recalc = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists:Joe Rogan Experience #200 - Duncan Trussell.mp4\n",
      "File already exists:Joe Rogan Experience #201 - EverLast.mp4\n",
      "File already exists:Joe Rogan Experience #202 - Dom Irrera.mp4\n",
      "File already exists:Joe Rogan Experience #203 - Jim Jefferies.mp4\n",
      "File already exists:Joe Rogan Experience #204 - Amy Schumer.mp4\n",
      "File already exists:Joe Rogan Experience #205  Neal Brennan.mp4\n",
      "File already exists:Joe Rogan Experience #206  Eddie Bravo.mp4\n",
      "File already exists:Joe Rogan Experience #208 - Freeway Rick Ross.mp4\n",
      "File already exists:Joe Rogan Experience #209 - Eddie Ifft.mp4\n",
      "File already exists:Joe Rogan Experience #210 - Joey Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #212 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #213 - Eddie Bravo.mp4\n",
      "File already exists:Joe Rogan Experience #214 - Duncan Trussell.mp4\n",
      "File already exists:Joe Rogan Experience #215 - Andrew Dice Clay.mp4\n",
      "File already exists:Joe Rogan Experience #216 - Chael Sonnen.mp4\n",
      "File already exists:Joe Rogan Experience #217 - Michael Ruppert.mp4\n",
      "File already exists:Joe Rogan Experience #218 - Dom Irrera.mp4\n",
      "File already exists:Joe Rogan Experience #219 - Joey Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #220 - Bert Kreischer.mp4\n",
      "File already exists:Joe Rogan Experience #221 - Shane Smith.mp4\n",
      "File already exists:Joe Rogan Experience #223 - Bobcat Goldthwait.mp4\n",
      "File already exists:Joe Rogan Experience #224 - Brian Redban.mp4\n",
      "File already exists:Joe Rogan Experience #225 - Urijah Faber.mp4\n",
      "File already exists:Joe Rogan Experience #226 - John Anthony West.mp4\n",
      "File already exists:Joe Rogan Experience #227 - Ari Shaffir.mp4\n",
      "File already exists:Joe Rogan Experience #228 - Bill Burr.mp4\n",
      "File already exists:Joe Rogan Experience #230 - Sam Sheridan.mp4\n",
      "File already exists:Joe Rogan Experience #231 - Dom Irrera.mp4\n",
      "File already exists:Joe Rogan Experience #232 - Giorgio Tsoukalos.mp4\n",
      "File already exists:Joe Rogan Experience #233 - Jim Norton.mp4\n",
      "File already exists:Joe Rogan Experience #234 - Adam Scorgie.mp4\n",
      "File already exists:Joe Rogan Experience #236 - Eddie Bravo.mp4\n",
      "File already exists:Joe Rogan Experience #237 - Tommy Chong.mp4\n",
      "File already exists:Joe Rogan Experience #238 - Kevin Pereira.mp4\n",
      "File already exists:Joe Rogan Experience #239 - Adam Kokesh.mp4\n",
      "File already exists:Joe Rogan Experience #241 - James 'Bobo' Fay.mp4\n",
      "File already exists:Joe Rogan Experience #242 - Justin Halpern.mp4\n",
      "File already exists:Joe Rogan Experience #243 - Honey Honey.mp4\n",
      "File already exists:Joe Rogan Experience #244 - Immortal Technique.mp4\n",
      "File already exists:Joe Rogan Experience #245 - Robb Wolf.mp4\n",
      "File already exists:Joe Rogan Experience #247 - Tito Ortiz.mp4\n",
      "File already exists:Joe Rogan Experience #248 - Tom Rhodes.mp4\n",
      "File already exists:Joe Rogan Experience #249 - Bert Kreischer.mp4\n",
      "File already exists:Joe Rogan Experience #250 - Joey 'CoCo' Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #251 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #252 - Jamie Kilstein.mp4\n",
      "File already exists:Joe Rogan Experience #253 - Andrew Dice Clay.mp4\n",
      "File already exists:Joe Rogan Experience #254 - Everlast.mp4\n",
      "File already exists:Joe Rogan Experience #255 - Duncan Trussell.mp4\n",
      "File already exists:Joe Rogan Experience #256 - David Seaman.mp4\n",
      "File already exists:Joe Rogan Experience #258 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #259 - Mike Birbiglia.mp4\n",
      "File already exists:Joe Rogan Experience #260 - Greg Fitzsimmons.mp4\n",
      "File already exists:Joe Rogan Experience #261 - Ari Shaffir.mp4\n",
      "File already exists:Joe Rogan Experience #262 - 'Freeway' Rick Ross.mp4\n",
      "File already exists:Joe Rogan Experience #266 - Rich Roll.mp4\n",
      "File already exists:Joe Rogan Experience #267 - Mac Danzig.mp4\n",
      "File already exists:Joe Rogan Experience #268 - Joey 'CoCo' Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #269 - Tait Fletcher.mp4\n",
      "File already exists:Joe Rogan Experience #270 - Kevin Pereira.mp4\n",
      "File already exists:Joe Rogan Experience #271 - London Real.mp4\n",
      "File already exists:Joe Rogan Experience #273 - Amber Lyon.mp4\n",
      "File already exists:Joe Rogan Experience #274 - Alex Grey.mp4\n",
      "File already exists:Joe Rogan Experience #275 - Dave Asprey.mp4\n",
      "File already exists:Joe Rogan Experience #277 - Victor Conte.mp4\n",
      "File already exists:Joe Rogan Experience #278 - Ari Shaffir.mp4\n",
      "File already exists:Joe Rogan Experience #279 - Duncan Trussell.mp4\n",
      "File already exists:Joe Rogan Experience #280 - Philip Coppens.mp4\n",
      "File already exists:Joe Rogan Experience #281 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #283 - Dave Attell.mp4\n",
      "File already exists:Joe Rogan Experience #284 - Daniel H. Wilson.mp4\n",
      "File already exists:Joe Rogan Experience #285 - Tim Ferriss.mp4\n",
      "File already exists:Joe Rogan Experience #286 - Daniele Bolelli.mp4\n",
      "File already exists:Joe Rogan Experience #287 - Les Stroud.mp4\n",
      "File already exists:Joe Rogan Experience #288 - Greg Proops.mp4\n",
      "File already exists:Joe Rogan Experience #289 - Shane Smith.mp4\n",
      "File already exists:Joe Rogan Experience #291 - Duncan Trussell.mp4\n",
      "File already exists:Joe Rogan Experience #292 - Eddie Bravo.mp4\n",
      "File already exists:Joe Rogan Experience #293 - Cara Santamaria.mp4\n",
      "File already exists:Joe Rogan Experience #294 - Ari Shaffir.mp4\n",
      "File already exists:Joe Rogan Experience #297 - Dom Irrera.mp4\n",
      "File already exists:Joe Rogan Experience #298 - Dennis McKenna.mp4\n",
      "File already exists:Joe Rogan Experience #299 - Honey Honey.mp4\n",
      "File already exists:Joe Rogan Experience #300 - Joey Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #301 - Doug Stanhope.mp4\n",
      "File already exists:Joe Rogan Experience #302 - Josh Barnett.mp4\n",
      "File already exists:Joe Rogan Experience #303 - Matt Vengrin.mp4\n",
      "File already exists:Joe Rogan Experience #304 - Andrew Dice Clay.mp4\n",
      "File already exists:Joe Rogan Experience #306 - Christopher Ryan.mp4\n",
      "File already exists:Joe Rogan Experience #307 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #308 - Steve Volk.mp4\n",
      "File already exists:Joe Rogan Experience #309 - Adam Hunter.mp4\n",
      "File already exists:Joe Rogan Experience #310 - Neil Degrasse Tyson.mp4\n",
      "File already exists:Joe Rogan Experience #311 - Ari Shaffir.mp4\n",
      "File already exists:Joe Rogan Experience #313 -  'Opie'.mp4\n",
      "File already exists:Joe Rogan Experience #314 - Ian Edwards.mp4\n",
      "File already exists:Joe Rogan Experience #315 - Jimmy Smith.mp4\n",
      "File already exists:Joe Rogan Experience #319 - Alex Honnold.mp4\n",
      "File already exists:Joe Rogan Experience #320 - Tim Ferriss.mp4\n",
      "File already exists:Joe Rogan Experience #321 - Melissa Etheridge.mp4\n",
      "File already exists:Joe Rogan Experience #322 - Ari Shaffir.mp4\n",
      "File already exists:Joe Rogan Experience #323 - 'Freeway' Rick Ross.mp4\n",
      "File already exists:Joe Rogan Experience #324 - Sam Sheridan.mp4\n",
      "File already exists:Joe Rogan Experience #325 - James 'The Colossus' Thompson.mp4\n",
      "File already exists:Joe Rogan Experience #327 - Dana White.mp4\n",
      "File already exists:Joe Rogan Experience #328 - Dan Carlin.mp4\n",
      "File already exists:Joe Rogan Experience #329 - Duncan Trussell.mp4\n",
      "File already exists:Joe Rogan Experience #330 - Eddie Huang.mp4\n",
      "File already exists:Joe Rogan Experience #331 - Dr. Steven Greer.mp4\n",
      "File already exists:Joe Rogan Experience #332 - Tom Segura.mp4\n",
      "File already exists:Joe Rogan Experience #333 - David Lee Roth.mp4\n",
      "File already exists:Joe Rogan Experience #334 - Dr. Amit Goswami.mp4\n",
      "File already exists:Joe Rogan Experience #335 - Bas Rutten.mp4\n",
      "File already exists:Joe Rogan Experience #336 - Scott Sigler.mp4\n",
      "File already exists:Joe Rogan Experience #337 - Justin Wren.mp4\n",
      "File already exists:Joe Rogan Experience #338 - Shane Smith.mp4\n",
      "File already exists:Joe Rogan Experience #339 - Jacob Ward.mp4\n",
      "File already exists:Joe Rogan Experience #340 - JD Kelley.mp4\n",
      "File already exists:Joe Rogan Experience #341 - Ben Hoffman.mp4\n",
      "File already exists:Joe Rogan Experience #342 - Dr. Christopher Ryan.mp4\n",
      "File already exists:Joe Rogan Experience #343 - Bill Burr.mp4\n",
      "File already exists:Joe Rogan Experience #345 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #346 - Douglas Rushkoff.mp4\n",
      "File already exists:Joe Rogan Experience #347 - Joey Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #349 - Greg Fitzsimmons.mp4\n",
      "File already exists:Joe Rogan Experience #350 - Tony Hinchcliffe.mp4\n",
      "File already exists:Joe Rogan Experience #351 - Georges St. Pierre.mp4\n",
      "File already exists:Joe Rogan Experience #352 - Tom Segura.mp4\n",
      "File already exists:Joe Rogan Experience #353 - Brian Redban.mp4\n",
      "File already exists:Joe Rogan Experience #355 - Dom Irrera.mp4\n",
      "File already exists:Joe Rogan Experience #356 - Dan Hardy.mp4\n",
      "File already exists:Joe Rogan Experience #357 - Daniele Bolelli.mp4\n",
      "File already exists:Joe Rogan Experience #358 - Bert Kreischer.mp4\n",
      "File already exists:Joe Rogan Experience #359 - Alex Grey.mp4\n",
      "File already exists:Joe Rogan Experience #360 - Graham Hancock.mp4\n",
      "File already exists:Joe Rogan Experience #362 - Eddie Ifft.mp4\n",
      "File already exists:Joe Rogan Experience #363 - Everlast.mp4\n",
      "File already exists:Joe Rogan Experience #364 - Tom Rhodes.mp4\n",
      "File already exists:Joe Rogan Experience #366 - Bobcat Goldthwait.mp4\n",
      "File already exists:Joe Rogan Experience #367 - Aubrey Marcus.mp4\n",
      "File already exists:Joe Rogan Experience #368 - David Seaman.mp4\n",
      "File already exists:Joe Rogan Experience #371 - Rick Doblin.mp4\n",
      "File already exists:Joe Rogan Experience #372 - Mariana van Zeller.mp4\n",
      "File already exists:Joe Rogan Experience #373 - Joey 'CoCo' Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #374 - Marc Maron.mp4\n",
      "File already exists:Joe Rogan Experience #375 - Shane Smith.mp4\n",
      "File already exists:Joe Rogan Experience #376 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #377 - Duncan Trussell.mp4\n",
      "File already exists:Joe Rogan Experience #378 - Dan Carlin.mp4\n",
      "File already exists:Joe Rogan Experience #380 - Tony Hinchcliffe.mp4\n",
      "File already exists:Joe Rogan Experience #381 - Abby Martin.mp4\n",
      "File already exists:Joe Rogan Experience #382 - Greg Fitzsimmons.mp4\n",
      "File already exists:Joe Rogan Experience #383 - Jim Norton.mp4\n",
      "File already exists:Joe Rogan Experience #384 - Ian McCall.mp4\n",
      "File already exists:Joe Rogan Experience #386 - Joey 'CoCo' Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #387 - Everlast.mp4\n",
      "File already exists:Joe Rogan Experience #389 - Brian Redban.mp4\n",
      "File already exists:Joe Rogan Experience #390 - Mac Lethal.mp4\n",
      "File already exists:Joe Rogan Experience #391 - Duncan Trussell.mp4\n",
      "File already exists:Joe Rogan Experience #392 - David Choe.mp4\n",
      "File already exists:Joe Rogan Experience #393 - Tom Segura.mp4\n",
      "File already exists:Joe Rogan Experience #395 - Kathleen Madigan.mp4\n",
      "File already exists:Joe Rogan Experience #396 - Stefan Molyneux.mp4\n",
      "File already exists:Joe Rogan Experience #398 - Sam Tripoli.mp4\n",
      "File already exists:Joe Rogan Experience #399 - Buck Angel.mp4\n",
      "File already exists:Joe Rogan Experience #401 - Doug Benson.mp4\n",
      "File already exists:Joe Rogan Experience #402 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #404 - Greg Proops.mp4\n",
      "File already exists:Joe Rogan Experience #407 - Eddie Bravo.mp4\n",
      "File already exists:Joe Rogan Experience #408 - Todd Glass.mp4\n",
      "File already exists:Joe Rogan Experience #409 - Pat Magee.mp4\n",
      "File already exists:Joe Rogan Experience #410 - Sam Harris.mp4\n",
      "File already exists:Joe Rogan Experience #411 - Dave Asprey.mp4\n",
      "File already exists:Joe Rogan Experience #412 - Maynard James Keenan.mp4\n",
      "File already exists:Joe Rogan Experience #414 - Cmdr. Chris Hadfield.mp4\n",
      "File already exists:Joe Rogan Experience #415 - Justin Foster.mp4\n",
      "File already exists:Joe Rogan Experience #416 - Ana Kasparian.mp4\n",
      "File already exists:Joe Rogan Experience #417 - Graham Hancock.mp4\n",
      "File already exists:Joe Rogan Experience #421 - Christopher Ryan.mp4\n",
      "File already exists:Joe Rogan Experience #422 - Greg Fitzsimmons.mp4\n",
      "File already exists:Joe Rogan Experience #423 - Gene LeBell.mp4\n",
      "File already exists:Joe Rogan Experience #424 - Brody Stevens.mp4\n",
      "File already exists:Joe Rogan Experience #425 - Phil Demers.mp4\n",
      "File already exists:Joe Rogan Experience #426 - Mike Birbiglia.mp4\n",
      "File already exists:Joe Rogan Experience #427 - Cliffy B.mp4\n",
      "File already exists:Joe Rogan Experience #428 - Tom Segura.mp4\n",
      "File already exists:Joe Rogan Experience #429 - Lee Camp.mp4\n",
      "File already exists:Joe Rogan Experience #432 - Joey 'CoCo' Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #434 - Roseanne Barr.mp4\n",
      "File already exists:Joe Rogan Experience #435 - Aubrey Marcus.mp4\n",
      "File already exists:Joe Rogan Experience #436 - Stefan Molyneux.mp4\n",
      "File already exists:Joe Rogan Experience #437 - Scott Sigler.mp4\n",
      "File already exists:Joe Rogan Experience #438 - Dr. Mark Gordon.mp4\n",
      "File already exists:Joe Rogan Experience #440 - Dom Irrera.mp4\n",
      "File already exists:Joe Rogan Experience #441 - Brian Dunning.mp4\n",
      "File already exists:Joe Rogan Experience #442 - Steven Rinella.mp4\n",
      "File already exists:Joe Rogan Experience #443 - Neal Brennan.mp4\n",
      "File already exists:Joe Rogan Experience #444 - John Hackleman.mp4\n",
      "File already exists:Joe Rogan Experience #445 - Peter Schiff.mp4\n",
      "File already exists:Joe Rogan Experience #446 - Andreas Antonopoulos.mp4\n",
      "File already exists:Joe Rogan Experience #447 - Cara Santa Maria.mp4\n",
      "File already exists:Joe Rogan Experience #448 - Tom Segura.mp4\n",
      "File already exists:Joe Rogan Experience #449 - Justin Martindale.mp4\n",
      "File already exists:Joe Rogan Experience #450 - Cameron Hanes.mp4\n",
      "File already exists:Joe Rogan Experience #451 - Aubrey Marcus.mp4\n",
      "File already exists:Joe Rogan Experience #454 - War Machine.mp4\n",
      "File already exists:Joe Rogan Experience #455 - Joey 'CoCo' Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #456 - Everlast.mp4\n",
      "File already exists:Joe Rogan Experience #457 - Ari Shaffir.mp4\n",
      "File already exists:Joe Rogan Experience #458 - Campbell McLaren.mp4\n",
      "File already exists:Joe Rogan Experience #459 - Dr. Rhonda Patrick.mp4\n",
      "File already exists:Joe Rogan Experience #460 - Kron Gracie.mp4\n",
      "File already exists:Joe Rogan Experience #461 - David Seaman.mp4\n",
      "File already exists:Joe Rogan Experience #463 - Louis Theroux.mp4\n",
      "File already exists:Joe Rogan Experience #465 - Greg Proops.mp4\n",
      "File already exists:Joe Rogan Experience #466 - Greg Fitzsimmons.mp4\n",
      "File already exists:Joe Rogan Experience #467 - Peter Giuliano.mp4\n",
      "File already exists:Joe Rogan Experience #469 - Dr. Carl Hart.mp4\n",
      "File already exists:Joe Rogan Experience #470 - Amber Lyon.mp4\n",
      "File already exists:Joe Rogan Experience #472 - Shane Smith.mp4\n",
      "File already exists:Joe Rogan Experience #473 - Jim Jefferies.mp4\n",
      "File already exists:Joe Rogan Experience #474 - Hannibal Buress.mp4\n",
      "File already exists:Joe Rogan Experience #475 - Adam Carolla.mp4\n",
      "File already exists:Joe Rogan Experience #476 - Honey Honey.mp4\n",
      "File already exists:Joe Rogan Experience #478 - Eddie Bravo.mp4\n",
      "File already exists:Joe Rogan Experience #479 - Joel Salatin.mp4\n",
      "File already exists:Joe Rogan Experience #483 - Mark Kendall.mp4\n",
      "File already exists:Joe Rogan Experience #484 - Alexis Ohanian.mp4\n",
      "File already exists:Joe Rogan Experience #485 - Amy Schumer.mp4\n",
      "File already exists:Joe Rogan Experience #487 - David Seaman.mp4\n",
      "File already exists:Joe Rogan Experience #488 - Iliza Shlesinger.mp4\n",
      "File already exists:Joe Rogan Experience #490 - Andreas Antonopoulos.mp4\n",
      "File already exists:Joe Rogan Experience #491 - Steve Maxwell.mp4\n",
      "File already exists:Joe Rogan Experience #492 - Dave Attell.mp4\n",
      "File already exists:Joe Rogan Experience #493 - Greg Fitzsimmons.mp4\n",
      "File already exists:Joe Rogan Experience #495 - Ian Edwards.mp4\n",
      "File already exists:Joe Rogan Experience #496 - Nick Cutter.mp4\n",
      "File already exists:Joe Rogan Experience #497 - Tim Kennedy.mp4\n",
      "File already exists:Joe Rogan Experience #498 - Aubrey Marcus.mp4\n",
      "File already exists:Joe Rogan Experience #499 - Cenk Uygur.mp4\n",
      "File already exists:Joe Rogan Experience #501 - Randall Carlson.mp4\n",
      "File already exists:Joe Rogan Experience #502 - Dr. Rhonda Patrick.mp4\n",
      "File already exists:Joe Rogan Experience #503 - Sam Tripoli.mp4\n",
      "File already exists:Joe Rogan Experience #504 - Steve Maxwell.mp4\n",
      "File already exists:Joe Rogan Experience #506 - Moshe Kasher.mp4\n",
      "File already exists:Joe Rogan Experience #507 - Bert Kreischer.mp4\n",
      "File already exists:Joe Rogan Experience #509 - Steve Hilton.mp4\n",
      "File already exists:Joe Rogan Experience #510 - Tony Hinchcliffe.mp4\n",
      "File already exists:Joe Rogan Experience #511 - Enson Inoue.mp4\n",
      "File already exists:Joe Rogan Experience #512 - Dan Savage.mp4\n",
      "File already exists:Joe Rogan Experience #513 - Joey 'CoCo' Diaz.mp4\n",
      "File already exists:Joe Rogan Experience #514 - Duke Roufus.mp4\n",
      "File already exists:Joe Rogan Experience #515 - Ari Shaffir.mp4\n",
      "File already exists:Joe Rogan Experience #518 - Matt Fulchiron.mp4\n",
      "File already exists:Joe Rogan Experience #519 - Gad Saad.mp4\n",
      "File already exists:Joe Rogan Experience #520 - David Seaman.mp4\n",
      "File already exists:Joe Rogan Experience #522 - CJ Werleman.mp4\n",
      "File already exists:Joe Rogan Experience #523 - Jim Norton.mp4\n",
      "File already exists:Joe Rogan Experience #525 - Bert Kreischer.mp4\n",
      "File already exists:Joe Rogan Experience #526 - Isaac Haxton.mp4\n",
      "File already exists:Joe Rogan Experience #527 - Ms. Pat.mp4\n",
      "File already exists:Joe Rogan Experience #529 - Abby Martin.mp4\n",
      "File already exists:Joe Rogan Experience #531 - Nick Youssef.mp4\n",
      "File already exists:Joe Rogan Experience #532 - Shooter Jennings.mp4\n",
      "File already exists:Joe Rogan Experience #533 - Chris D'Elia.mp4\n",
      "File already exists:Joe Rogan Experience #534 - Robin Black.mp4\n",
      "File already exists:Joe Rogan Experience #535 - Scroobius Pip.mp4\n",
      "File already exists:Joe Rogan Experience #536 - Joe Quirk.mp4\n",
      "File already exists:Joe Rogan Experience #537 - Rich Vos.mp4\n",
      "File already exists:Joe Rogan Experience #538 - Stefan Molyneux.mp4\n",
      "File already exists:Joe Rogan Experience #539 - Cara Santa Maria.mp4\n",
      "File already exists:Joe Rogan Experience #540 - Steven Rinella.mp4\n",
      "File already exists:Joe Rogan Experience #541 - Mike Baker.mp4\n",
      "File already exists:Joe Rogan Experience #542 - Greg Fitzsimmons.mp4\n",
      "File already exists:Joe Rogan Experience #543 - Sam Harris.mp4\n",
      "File already exists:Joe Rogan Experience #544 - Dom Irrera.mp4\n",
      "File already exists:Joe Rogan Experience #545 - Tony Hinchcliffe.mp4\n",
      "File already exists:Joe Rogan Experience #546 - Mike Dolce.mp4\n",
      "File already exists:Joe Rogan Experience #547 - Joe DeRosa.mp4\n",
      "File already exists:Joe Rogan Experience #548 - Tim Burnett.mp4\n",
      "File already exists:Joe Rogan Experience #549 - Big Jay Oakerson.mp4\n",
      "File already exists:Joe Rogan Experience #550 - Rupert Sheldrake.mp4\n",
      "File already exists:Joe Rogan Experience #551 - Graham Hancock.mp4\n",
      "File already exists:Joe Rogan Experience #552 - Kid Cudi.mp4\n",
      "File already exists:Joe Rogan Experience #553 - Thaddeus Russell.mp4\n",
      "File already exists:Joe Rogan Experience #554 - W. Kamau Bell.mp4\n",
      "File already exists:Joe Rogan Experience #555 - Rory Albanese.mp4\n",
      "File already exists:Joe Rogan Experience #556 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #557 - Bryan Callen.mp4\n",
      "File already exists:Joe Rogan Experience #558 - Honey Honey.mp4\n",
      "File already exists:Joe Rogan Experience #559 - Keith Weber.mp4\n",
      "File already exists:Joe Rogan Experience #560 - Anthony Cumia.mp4\n",
      "File already exists:Joe Rogan Experience #561 - Bruce Damer.mp4\n",
      "File already exists:Joe Rogan Experience #562 - Paul Stanley.mp4\n",
      "File already exists:Joe Rogan Experience #563 - David Choe.mp4\n",
      "File already exists:Joe Rogan Experience #564 - Sturgill Simpson.mp4\n",
      "File already exists:Joe Rogan Experience #565 - Trevor Valle.mp4\n",
      "File already exists:Joe Rogan Experience #566 - Sue Aikens.mp4\n",
      "File already exists:Joe Rogan Experience #567 - Cameron Hanes.mp4\n",
      "File already exists:Joe Rogan Experience #568 - Dr. Rhonda Patrick.mp4\n",
      "File already exists:Joe Rogan Experience #569 - Joe Perry.mp4\n",
      "File already exists:Joe Rogan Experience #570 - Ryan Parsons.mp4\n",
      "File already exists:Joe Rogan Experience #571 - Josh Zepps.mp4\n",
      "File already exists:Joe Rogan Experience #573 - Daniele Bolelli.mp4\n",
      "File already exists:Joe Rogan Experience #575 - Matt Fulchiron.mp4\n",
      "File already exists:Joe Rogan Experience #576 - Jim Shockey.mp4\n",
      "File already exists:Joe Rogan Experience #577 - Duncan Trussell.mp4\n",
      "File already exists:Joe Rogan Experience #578 - Peter McGraw.mp4\n",
      "File already exists:Joe Rogan Experience #579 - Rory MacDonald.mp4\n",
      "File already exists:Joe Rogan Experience #581 - Andreas Antonopoulos.mp4\n",
      "File already exists:Joe Rogan Experience #582 - David Seaman.mp4\n",
      "File already exists:Joe Rogan Experience #583 - Bill Burr.mp4\n",
      "File already exists:Joe Rogan Experience #584 - Zoltan Istvan.mp4\n",
      "File already exists:Joe Rogan Experience #585 - John Heffron.mp4\n",
      "File already exists:Joe Rogan Experience #587 - Ron Finley.mp4\n",
      "File already exists:Joe Rogan Experience #588 - Philip DeFranco.mp4\n",
      "File already exists:Joe Rogan Experience #589 - Chris Harris.mp4\n",
      "File already exists:Joe Rogan Experience #590 - Ana Kasparian.mp4\n",
      "File already exists:Joe Rogan Experience #591 - Kevin Pereira.mp4\n",
      "File already exists:Joe Rogan Experience #592 - Bert Kreischer.mp4\n",
      "File already exists:Joe Rogan Experience #593 - Josh Fox.mp4\n",
      "File already exists:Joe Rogan Experience #594 - Russell Peters.mp4\n",
      "File already exists:Joe Rogan Experience #595 - Nick DiPaolo.mp4\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import unquote\n",
    "import urllib.request\n",
    "#download videos from archive.org\n",
    "\n",
    "#get files in https://archive.org/download/jre-001-837/JRE_001-837/\n",
    "#code from https://www.geeksforgeeks.org/extract-all-the-urls-from-the-webpage-using-python/\n",
    "url = 'https://archive.org/download/jre-001-837/JRE_001-837/'\n",
    "reqs = requests.get(url)\n",
    "soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "urls = []\n",
    "for link in soup.find_all('a'):\n",
    "    urls.append(link.get('href'))\n",
    "\n",
    "#download files that only have a single person (no ampersand or comma) that isn't a fight companion and also between 200 and 700\n",
    "#also, no partial episodes\n",
    "list_dlurl = []\n",
    "for url in urls:\n",
    "    if url is None:\n",
    "        continue\n",
    "    #allow PHD\n",
    "    str_temp = url.replace('%2C%20PhD','')\n",
    "    if not '.mp4' in str_temp:\n",
    "        continue\n",
    "    if '.ia.mp4' in str_temp:\n",
    "        continue\n",
    "    if 'Part' in str_temp: #remove multi-part episodes\n",
    "        continue\n",
    "    if '%2C' in str_temp: #remove comma\n",
    "        continue\n",
    "    if '%26' in str_temp: #remove ampersand\n",
    "        continue\n",
    "    if 'McAfee' in str_temp: #McAfee interview conducted over phone\n",
    "        continue\n",
    "\n",
    "    \n",
    "    str_epnum = str_temp.split('%23')[1]\n",
    "    str_epnum = str_epnum.split('%20')[0]\n",
    "    int_epnum = int(str_epnum)\n",
    "    #they up the file size after 595\n",
    "    if int_epnum < 200 or int_epnum > 595:\n",
    "        continue\n",
    "    list_dlurl.append(url)\n",
    "\n",
    "for dlurl in list_dlurl:\n",
    "    # check if file already exists in downloads folder before downloading\n",
    "    filename = unquote(dlurl)\n",
    "    if os.path.exists(ENV_FOLDER_DATA + filename):\n",
    "        print('File already exists:' + filename)\n",
    "        continue\n",
    "    url_final = 'https://archive.org/download/jre-001-837/JRE_001-837/' + dlurl\n",
    "    print('Downloading:' + filename)\n",
    "    urllib.request.urlretrieve(url_final, ENV_FOLDER_DATA + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode=200 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #200 - Duncan Trussell.mp4\n",
      "Speaker diarization exists:E:\\W4732 Computer Vision\\Final Paper Data Proc\\segmentation\\200.psv\n",
      "Episode=200 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #200 - Duncan Trussell.mp4\n",
      "Pratt data already generated:E:\\W4732 Computer Vision\\Final Paper Data Proc\\pratt\\200.pickle\n",
      "Episode=201 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #201 - EverLast.mp4\n",
      "Speaker diarization exists:E:\\W4732 Computer Vision\\Final Paper Data Proc\\segmentation\\201.psv\n",
      "Episode=201 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #201 - EverLast.mp4\n",
      "Pratt data already generated:E:\\W4732 Computer Vision\\Final Paper Data Proc\\pratt\\201.pickle\n",
      "Episode=202 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #202 - Dom Irrera.mp4\n",
      "Speaker diarization exists:E:\\W4732 Computer Vision\\Final Paper Data Proc\\segmentation\\202.psv\n",
      "Episode=202 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #202 - Dom Irrera.mp4\n",
      "Pratt data already generated:E:\\W4732 Computer Vision\\Final Paper Data Proc\\pratt\\202.pickle\n",
      "Episode=203 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #203 - Jim Jefferies.mp4\n",
      "Speaker diarization exists:E:\\W4732 Computer Vision\\Final Paper Data Proc\\segmentation\\203.psv\n",
      "Episode=203 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #203 - Jim Jefferies.mp4\n",
      "Pratt data already generated:E:\\W4732 Computer Vision\\Final Paper Data Proc\\pratt\\203.pickle\n",
      "Episode=204 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #204 - Amy Schumer.mp4\n",
      "Speaker diarization exists:E:\\W4732 Computer Vision\\Final Paper Data Proc\\segmentation\\204.psv\n",
      "Episode=204 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #204 - Amy Schumer.mp4\n",
      "Pratt data already generated:E:\\W4732 Computer Vision\\Final Paper Data Proc\\pratt\\204.pickle\n",
      "Episode=205 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #205  Neal Brennan.mp4\n",
      "Speaker diarization exists:E:\\W4732 Computer Vision\\Final Paper Data Proc\\segmentation\\205.psv\n",
      "Episode=205 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #205  Neal Brennan.mp4\n",
      "Pratt data already generated:E:\\W4732 Computer Vision\\Final Paper Data Proc\\pratt\\205.pickle\n",
      "Episode=206 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #206  Eddie Bravo.mp4\n",
      "Speaker diarization exists:E:\\W4732 Computer Vision\\Final Paper Data Proc\\segmentation\\206.psv\n",
      "Episode=206 at E:\\W4732 Computer Vision\\Final Paper Data\\Joe Rogan Experience #206  Eddie Bravo.mp4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "for path_mp4 in glob.glob(ENV_FOLDER_DATA + '*.mp4'):\n",
    "    filesuf_mp4 = os.path.basename(path_mp4)\n",
    "    process_mp4s_for_processing(filesuf_mp4)\n",
    "    process_mp4s_for_analysis(filesuf_mp4, recalc = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to fill out speakers first\n",
    "process_analysis_for_model(filesuf_mp4, recalc = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Appendix </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%script` not found.\n"
     ]
    }
   ],
   "source": [
    "##Appendix 1##\n",
    "# Failed Speaker Diarization 1\n",
    "%%script echo skipping appendix\n",
    "\n",
    "#https://medium.com/@apparaomulpuri/speaker-diarization-in-python-a-step-by-step-guide-351a094237f2\n",
    "#perform speaker diarization (lingo for \"speaker recognition\")\n",
    "#this is a poorly performing solution\n",
    "\n",
    "import librosa #after further analysis librosa is actually a music library - seems cool\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def generate_speaker_labels(filepath_wav):\n",
    "    audio, sr = librosa.load(filepath_wav, sr=None)\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "    #print('Duration:' + str(duration))\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    mfccs_scaled = scaler.fit_transform(mfccs.T)\n",
    "    kmeans = KMeans(n_clusters=3)  # Adjust based on the expected number of speakers\n",
    "    speaker_labels = kmeans.fit_predict(mfccs_scaled)\n",
    "\n",
    "    del audio\n",
    "    del sr\n",
    "    del mfccs\n",
    "    del scaler\n",
    "    del mfccs_scaled\n",
    "    del kmeans\n",
    "\n",
    "    return speaker_labels, duration\n",
    "    \n",
    "list_speakers , duration = generate_speaker_labels(filepath_testwav)\n",
    "\n",
    "#print(len(list_speakers))\n",
    "# 917952\n",
    "# sample rate = 22050\n",
    "# hop length = 512\n",
    "#print(str( len(list_speakers) / duration))\n",
    "#86.13282789423312 <- samples per second\n",
    "#print(str((60*60*2) + (60 * 57) + 39))\n",
    "\n",
    "#now that we have categorizations, let's perform cutoffs to split the speech (and video) between the speakers:\n",
    "samples_per_sec = 1.0 * len(list_speakers) / duration\n",
    "list_cutoffs = []\n",
    "current_speaker = list_speakers[0]\n",
    "temp_dict = {}\n",
    "temp_dict['speaker'] = current_speaker\n",
    "temp_dict['start_index'] = 0\n",
    "for i,speaker in enumerate(list_speakers):\n",
    "    if speaker == temp_dict['speaker'] and (i != (len(list_speakers) - 1)):\n",
    "        continue\n",
    "    temp_dict['end_index'] = i - 1\n",
    "    list_cutoffs.append(temp_dict)\n",
    "    temp_dict = {}\n",
    "    temp_dict['speaker'] = speaker\n",
    "    temp_dict['start_index'] = i\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "audio = AudioSegment.from_wav(filepath_testwav)\n",
    "\n",
    "\n",
    "for  idx,dict_tim in enumerate(list_cutoffs):\n",
    "    start = int((dict_tim['start_index'] / samples_per_sec) * 1000) #pydub works in millisec\n",
    "    end = int((dict_tim['end_index'] / samples_per_sec) * 1000) #pydub works in millisec\n",
    "    audio_chunk=audio[start:end]\n",
    "    audio_chunk.export( ENV_FOLDER_DATA_PROC + '568\\\\' + str(end) + '-'  + str(dict_tim['speaker'])  + \".wav\", format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%script` not found.\n"
     ]
    }
   ],
   "source": [
    "##Appendix 2##\n",
    "# Failed Speaker Diarization 2\n",
    "%%script echo skipping appendix\n",
    "\n",
    "#perform speaker diarization (lingo for \"speaker recognition\")\n",
    "#attempt 2\n",
    "#This is using old code thus will not run\n",
    "#https://picovoice.ai/blog/speaker-diarization-in-python/\n",
    "#https://speechbrain.github.io/ \n",
    "#https://colab.research.google.com/drive/1nMKHOTTROwQitOXQEYq35lvv7nyTOlpe?usp=sharing\n",
    "from simple_diarizer.diarizer import Diarizer\n",
    "\n",
    "diar = Diarizer(\n",
    "        embed_model='ecapa', # supported types: ['xvec', 'ecapa']\n",
    "        cluster_method='sc', # supported types: ['ahc', 'sc']\n",
    "        window=1.5, # size of window to extract embeddings (in seconds)\n",
    "        period=0.75 # hop of window (in seconds)\n",
    "    )\n",
    "segments = diar.diarize(filepath_testwav, \n",
    "                        num_speakers=None,\n",
    "                        threshold=1e-1,\n",
    "                        outfile=ENV_FOLDER_DATA_PROC + '568\\\\segment.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix 3 - code to transcribe text\n",
    "\n",
    "# Import the required libraries\n",
    "import speech_recognition as sr  # Library for speech recognition\n",
    "import os  # Library for interacting with the operating system\n",
    "from pydub import AudioSegment  # Library for working with audio files\n",
    "from pydub.silence import split_on_silence  # Function for splitting audio files based on silence\n",
    "\n",
    "#https://stackoverflow.com/questions/65489705/transcribing-mp3-to-text-python-riff-id-error\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def transcribe_large_audio_file(prefix,path_mp3):\n",
    "    \"\"\"\n",
    "    Split audio into chunks and apply speech recognition\n",
    "    \"\"\"\n",
    "    # Load audio file with pydub\n",
    "    audio = AudioSegment.from_mp3(path_mp3)\n",
    "    # Split audio at silent parts with duration of 700ms or more and obtain chunks\n",
    "    audio_chunks = split_on_silence(audio, min_silence_len=600, silence_thresh=audio.dBFS-14, keep_silence=600)\n",
    "\n",
    "    # Create a directory to store audio chunks\n",
    "    chunks_dir = ENV_FOLDER_DATA_PROC + prefix\n",
    "    if not os.path.isdir(chunks_dir):\n",
    "        os.mkdir(chunks_dir)\n",
    "\n",
    "    full_text = \"\"\n",
    "    failed_attempts = 0\n",
    "    # Process each audio chunk\n",
    "    for i, chunk in enumerate(audio_chunks, start=1):\n",
    "        # Save chunk in the directory\n",
    "        chunk_file_name = os.path.join(chunks_dir, f\"chunk{i}.wav\")\n",
    "        chunk.export(chunk_file_name, format=\"wav\")\n",
    "        # Recognize audio from the chunk\n",
    "        with sr.WavFile(chunk_file_name) as src:\n",
    "            listened_audio = recognizer.listen(src)\n",
    "            # Convert audio to text\n",
    "            try:\n",
    "                text = recognizer.recognize_whisper(listened_audio)\n",
    "            except Exception  as e:\n",
    "                failed_attempts += 1\n",
    "                print(e)\n",
    "            else:\n",
    "                failed_attempts = 0\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_file_name, \":\", text)\n",
    "                full_text += text\n",
    "    # Return the transcription for all chunks\n",
    "    return full_text\n",
    "\n",
    "def split_and_transcribe(prefix,filepath_mp3):\n",
    "    # Define the output directory\n",
    "    output_dir = ENV_FOLDER_DATA_PROC + prefix\n",
    "\n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate through all .mp3 files in the directory and transcribe them\n",
    "    with open(os.path.join(output_dir, '568.txt'), 'w') as result_file:\n",
    "        print(f\"Processing {filepath_mp3}\")\n",
    "        try:\n",
    "            # Transcribe the audio file\n",
    "            transcription = transcribe_large_audio_file(prefix,filepath_mp3)\n",
    "        except LookupError as error:\n",
    "            # If there is an error, skip the file and continue with the next one\n",
    "            print(f\"Error on {filepath_mp3} due to: {error}\")\n",
    "        # Save the transcription to a text file with the same name as the audio file\n",
    "        txt_file_path = os.path.join(output_dir, f\"{os.path.splitext(filepath_mp3)[0]}.txt\")\n",
    "        with open(txt_file_path, 'w', encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(transcription)\n",
    "        # Print the transcription and the path to the saved text file\n",
    "        print(transcription)\n",
    "        print(f\"Transcription saved to {txt_file_path}\")\n",
    "        # Save the transcription to the result\n",
    "\n",
    "\n",
    "split_and_transcribe('568',filepath_testmp3)\n",
    "#splitting file into pieces\n",
    "#https://stackoverflow.com/questions/67334379/cut-mp4-in-pieces-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
