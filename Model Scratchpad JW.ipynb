{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in e:\\python310\\lib\\site-packages (1.4)\n",
      "Requirement already satisfied: av in e:\\python310\\lib\\site-packages (12.0.0)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in e:\\python310\\lib\\site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: torchvision in e:\\python310\\lib\\site-packages (0.17.2+cu121)\n",
      "Requirement already satisfied: torchaudio in e:\\python310\\lib\\site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: filelock in e:\\python310\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\python310\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in e:\\python310\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in e:\\python310\\lib\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in e:\\python310\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in e:\\python310\\lib\\site-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: numpy in e:\\python310\\lib\\site-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\python310\\lib\\site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\python310\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in e:\\python310\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "#package installs\n",
    "#E:\\Python310\\python.exe -m pip install --upgrade pip\n",
    "#!E:\\Python310\\python.exe -m pip install git+https://github.com/openai/whisper.git soundfile\n",
    "!E:\\Python310\\Scripts\\pip3.exe install ffmpeg av\n",
    "#!E:\\Python310\\python.exe -m pip uninstall torch torchvision torchaudio -y\n",
    "!E:\\Python310\\python.exe -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV_HOSTNAME:JWGamingPC\n",
      "ENV_FOLDER_DATA:E:\\W4732 Computer Vision\\Final Paper Data\\\n",
      "ENV_PRATT:\n"
     ]
    }
   ],
   "source": [
    "#Global variables\n",
    "import socket\n",
    "import os\n",
    "ENV_HOSTNAME = socket.gethostname()\n",
    "print('ENV_HOSTNAME:' + ENV_HOSTNAME)\n",
    "\n",
    "#store defaults for Jacob here:\n",
    "ENV_FOLDER_DATA = 'C:\\\\Users\\\\jakes\\\\Documents\\\\COMS 4732 - Computer Vision\\\\W4732CompVisFinal\\\\Data\\\\'\n",
    "ENV_FOLDER_DATA_PROC = 'C:\\\\Users\\\\jakes\\\\Documents\\\\COMS 4732 - Computer Vision\\\\W4732CompVisFinal\\\\Data_Proc\\\\'\n",
    "ENV_PRATT = ''\n",
    "\n",
    "\n",
    "if ENV_HOSTNAME == 'JWGamingPC':\n",
    "    ENV_FOLDER_DATA = 'E:\\\\W4732 Computer Vision\\\\Final Paper Data\\\\'\n",
    "    ENV_FOLDER_DATA_PROC = 'E:\\\\W4732 Computer Vision\\\\Final Paper Data Proc\\\\'\n",
    "    ENV_PRATT = ''\n",
    "\n",
    "print('ENV_FOLDER_DATA:' + ENV_FOLDER_DATA)\n",
    "print('ENV_PRATT:' + ENV_PRATT)\n",
    "\n",
    "# Create folder structure\n",
    "import os\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'segmentation', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'targetdf', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'pratt', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'eps', exist_ok=True)\n",
    "os.makedirs(ENV_FOLDER_DATA_PROC + 'clips', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JWVideoConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv3d(1, 4, kernel_size=(15, 15, 15), stride=(5, 5, 5), padding=(3, 3, 3))\n",
       "    (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Sigmoid()\n",
       "    (3): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=26460, out_features=4096, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (fc3): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=41, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create model result\n",
    "#PATH_MODEL = ENV_FOLDER_DATA_PROC + 'charts\\\\' + 'pitchVidNetV3.pt'\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class JWVideoConvNet(torch.nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=41):\n",
    "        super().__init__()\n",
    "        # TODO: Initialize network layers\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(in_channels=in_channels, out_channels=4, kernel_size=15, padding=3, stride=5),\n",
    "            torch.nn.BatchNorm3d(4),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        #self.layer2 = torch.nn.Sequential(\n",
    "        #    torch.nn.Conv3d(in_channels=4, out_channels=8, kernel_size=8, padding=1, stride=2),\n",
    "            #torch.nn.BatchNorm3d(16),\n",
    "        #    torch.nn.Sigmoid(),\n",
    "            #torch.nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #    )\n",
    "        #self.layer3 = torch.nn.Sequential(\n",
    "        #    torch.nn.Conv3d(in_channels=8, out_channels=16, kernel_size=3, padding=1, stride=1),\n",
    "            #torch.nn.BatchNorm3d(32),\n",
    "        #    torch.nn.Sigmoid(),\n",
    "            #torch.nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        #    )\n",
    "        # self.layer4 = nn.Sequential(\n",
    "        #     nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "        #     nn.BatchNorm2d(128),\n",
    "        #     nn.LeakyReLU(),\n",
    "        #     nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(26460, 4096),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Dropout(0.1))\n",
    "        self.fc2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(4096, 1024),\n",
    "            torch.nn.Sigmoid(),\n",
    "            torch.nn.Dropout(0.1))\n",
    "        self.fc3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1024, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement the forward pass with using the layers defined above\n",
    "        #       and the proper activation functions\n",
    "        #print(\"input: \", x.shape)\n",
    "        x = self.layer1(x)\n",
    "        #print(\"layer1: \", x.shape)\n",
    "        #x = self.layer2(x)\n",
    "        #print(\"layer2: \", x.shape) \n",
    "        #x = self.layer3(x)\n",
    "        #print(\"layer3: \", x.shape)\n",
    "        #x = self.layer4(x)\n",
    "        #print(\"layer4: \", x.shape)\n",
    "        x = torch.flatten(x,1)\n",
    "        #print(\"flatten: \", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        #print(\"fc1: \", x.shape)\n",
    "        x = self.fc2(x)\n",
    "        #print(\"fc2: \", x.shape)\n",
    "        x = self.fc3(x)\n",
    "        #print(\"fc3: \", x.shape)\n",
    "        return x\n",
    "\n",
    "a = JWVideoConvNet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#a.load_state_dict(torch.load(ENV_FOLDER_DATA_PROC + 'charts\\\\' + 'JWPitchModv01.pt'))\n",
    "a.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Epoch=1 Loss=0.021\n",
      "Epoch=1 Loss=0.026\n",
      "Epoch=1 Loss=0.015\n",
      "Epoch=1 Loss=0.030\n",
      "Epoch=1 Loss=0.033\n",
      "Epoch=1 Loss=0.031\n",
      "Epoch=1 Loss=0.049\n",
      "Epoch=1 Loss=0.022\n",
      "Epoch=1 Loss=0.039\n",
      "Epoch=1 Loss=0.043\n",
      "Epoch=1 Loss=0.040\n",
      "Epoch=1 Loss=0.025\n",
      "Epoch=1 Loss=0.012\n",
      "Epoch=1 Loss=0.056\n",
      "Epoch=1 Loss=0.015\n",
      "Epoch:1\n",
      "Epoch=2 Loss=0.013\n",
      "Epoch=2 Loss=0.019\n",
      "Epoch=2 Loss=0.046\n",
      "Epoch=2 Loss=0.010\n",
      "Epoch=2 Loss=0.028\n",
      "Epoch=2 Loss=0.050\n",
      "Epoch=2 Loss=0.028\n",
      "Epoch=2 Loss=0.073\n",
      "Epoch=2 Loss=0.049\n",
      "Epoch=2 Loss=0.016\n",
      "Epoch=2 Loss=0.021\n",
      "Epoch=2 Loss=0.046\n",
      "Epoch=2 Loss=0.013\n",
      "Epoch=2 Loss=0.017\n",
      "Epoch=2 Loss=0.033\n",
      "Epoch:2\n",
      "Epoch=3 Loss=0.029\n",
      "Epoch=3 Loss=0.008\n",
      "Epoch=3 Loss=0.026\n",
      "Epoch=3 Loss=0.020\n",
      "Epoch=3 Loss=0.025\n",
      "Epoch=3 Loss=0.046\n",
      "Epoch=3 Loss=0.025\n",
      "Epoch=3 Loss=0.047\n",
      "Epoch=3 Loss=0.021\n",
      "Epoch=3 Loss=0.016\n",
      "Epoch=3 Loss=0.023\n",
      "Epoch=3 Loss=0.105\n",
      "Epoch=3 Loss=0.013\n",
      "Epoch=3 Loss=0.038\n",
      "Epoch=3 Loss=0.013\n",
      "Epoch:3\n",
      "Epoch=4 Loss=0.016\n",
      "Epoch=4 Loss=0.074\n",
      "Epoch=4 Loss=0.047\n",
      "Epoch=4 Loss=0.022\n",
      "Epoch=4 Loss=0.027\n",
      "Epoch=4 Loss=0.013\n",
      "Epoch=4 Loss=0.060\n",
      "Epoch=4 Loss=0.052\n",
      "Epoch=4 Loss=0.034\n",
      "Epoch=4 Loss=0.056\n",
      "Epoch=4 Loss=0.042\n",
      "Epoch=4 Loss=0.022\n",
      "Epoch=4 Loss=0.017\n",
      "Epoch=4 Loss=0.040\n",
      "Epoch=4 Loss=0.033\n",
      "Epoch:4\n",
      "Epoch=5 Loss=0.025\n",
      "Epoch=5 Loss=0.013\n",
      "Epoch=5 Loss=0.015\n",
      "Epoch=5 Loss=0.038\n",
      "Epoch=5 Loss=0.033\n",
      "Epoch=5 Loss=0.014\n",
      "Epoch=5 Loss=0.089\n",
      "Epoch=5 Loss=0.009\n",
      "Epoch=5 Loss=0.026\n",
      "Epoch=5 Loss=0.024\n",
      "Epoch=5 Loss=0.034\n",
      "Epoch=5 Loss=0.042\n",
      "Epoch=5 Loss=0.024\n",
      "Epoch=5 Loss=0.027\n",
      "Epoch=5 Loss=0.017\n",
      "Epoch:5\n",
      "Epoch=6 Loss=0.050\n",
      "Epoch=6 Loss=0.029\n",
      "Epoch=6 Loss=0.023\n",
      "Epoch=6 Loss=0.014\n",
      "Epoch=6 Loss=0.026\n",
      "Epoch=6 Loss=0.022\n",
      "Epoch=6 Loss=0.082\n",
      "Epoch=6 Loss=0.059\n",
      "Epoch=6 Loss=0.019\n",
      "Epoch=6 Loss=0.021\n",
      "Epoch=6 Loss=0.031\n",
      "Epoch=6 Loss=0.039\n",
      "Epoch=6 Loss=0.028\n",
      "Epoch=6 Loss=0.039\n",
      "Epoch=6 Loss=0.022\n",
      "Epoch:6\n",
      "Epoch=7 Loss=0.020\n",
      "Epoch=7 Loss=0.126\n",
      "Epoch=7 Loss=0.034\n",
      "Epoch=7 Loss=0.026\n",
      "Epoch=7 Loss=0.030\n",
      "Epoch=7 Loss=0.042\n",
      "Epoch=7 Loss=0.025\n",
      "Epoch=7 Loss=0.027\n",
      "Epoch=7 Loss=0.033\n",
      "Epoch=7 Loss=0.019\n",
      "Epoch=7 Loss=0.032\n",
      "Epoch=7 Loss=0.027\n",
      "Epoch=7 Loss=0.020\n",
      "Epoch=7 Loss=0.015\n",
      "Epoch=7 Loss=0.016\n",
      "Epoch:7\n",
      "Epoch=8 Loss=0.021\n",
      "Epoch=8 Loss=0.014\n",
      "Epoch=8 Loss=0.018\n",
      "Epoch=8 Loss=0.021\n",
      "Epoch=8 Loss=0.037\n",
      "Epoch=8 Loss=0.031\n",
      "Epoch=8 Loss=0.032\n",
      "Epoch=8 Loss=0.015\n",
      "Epoch=8 Loss=0.085\n",
      "Epoch=8 Loss=0.042\n",
      "Epoch=8 Loss=0.029\n",
      "Epoch=8 Loss=0.047\n",
      "Epoch=8 Loss=0.046\n",
      "Epoch=8 Loss=0.113\n",
      "Epoch=8 Loss=0.034\n",
      "Epoch:8\n",
      "Epoch=9 Loss=0.038\n",
      "Epoch=9 Loss=0.027\n",
      "Epoch=9 Loss=0.036\n",
      "Epoch=9 Loss=0.040\n",
      "Epoch=9 Loss=0.016\n",
      "Epoch=9 Loss=0.030\n",
      "Epoch=9 Loss=0.041\n",
      "Epoch=9 Loss=0.011\n",
      "Epoch=9 Loss=0.032\n",
      "Epoch=9 Loss=0.022\n",
      "Epoch=9 Loss=0.014\n",
      "Epoch=9 Loss=0.011\n",
      "Epoch=9 Loss=0.025\n",
      "Epoch=9 Loss=0.052\n",
      "Epoch=9 Loss=0.014\n",
      "Epoch:9\n",
      "Epoch=10 Loss=0.027\n",
      "Epoch=10 Loss=0.086\n",
      "Epoch=10 Loss=0.026\n",
      "Epoch=10 Loss=0.021\n",
      "Epoch=10 Loss=0.012\n",
      "Epoch=10 Loss=0.028\n",
      "Epoch=10 Loss=0.016\n",
      "Epoch=10 Loss=0.026\n",
      "Epoch=10 Loss=0.025\n",
      "Epoch=10 Loss=0.024\n",
      "Epoch=10 Loss=0.043\n",
      "Epoch=10 Loss=0.025\n",
      "Epoch=10 Loss=0.029\n",
      "Epoch=10 Loss=0.038\n",
      "Epoch=10 Loss=0.032\n",
      "Epoch:10\n",
      "Epoch=11 Loss=0.008\n",
      "Epoch=11 Loss=0.012\n",
      "Epoch=11 Loss=0.059\n",
      "Epoch=11 Loss=0.014\n",
      "Epoch=11 Loss=0.044\n",
      "Epoch=11 Loss=0.017\n",
      "Epoch=11 Loss=0.036\n",
      "Epoch=11 Loss=0.032\n",
      "Epoch=11 Loss=0.029\n",
      "Epoch=11 Loss=0.036\n",
      "Epoch=11 Loss=0.022\n",
      "Epoch=11 Loss=0.035\n",
      "Epoch=11 Loss=0.024\n",
      "Epoch=11 Loss=0.012\n",
      "Epoch=11 Loss=0.020\n",
      "Epoch:11\n",
      "Epoch=12 Loss=0.020\n",
      "Epoch=12 Loss=0.045\n",
      "Epoch=12 Loss=0.017\n",
      "Epoch=12 Loss=0.053\n",
      "Epoch=12 Loss=0.039\n",
      "Epoch=12 Loss=0.034\n",
      "Epoch=12 Loss=0.015\n",
      "Epoch=12 Loss=0.025\n",
      "Epoch=12 Loss=0.034\n",
      "Epoch=12 Loss=0.023\n",
      "Epoch=12 Loss=0.062\n",
      "Epoch=12 Loss=0.019\n",
      "Epoch=12 Loss=0.028\n",
      "Epoch=12 Loss=0.039\n",
      "Epoch=12 Loss=0.033\n",
      "Epoch:12\n",
      "Epoch=13 Loss=0.034\n",
      "Epoch=13 Loss=0.008\n",
      "Epoch=13 Loss=0.016\n",
      "Epoch=13 Loss=0.062\n",
      "Epoch=13 Loss=0.024\n",
      "Epoch=13 Loss=0.048\n",
      "Epoch=13 Loss=0.022\n",
      "Epoch=13 Loss=0.063\n",
      "Epoch=13 Loss=0.013\n",
      "Epoch=13 Loss=0.028\n",
      "Epoch=13 Loss=0.050\n",
      "Epoch=13 Loss=0.012\n",
      "Epoch=13 Loss=0.027\n",
      "Epoch=13 Loss=0.040\n",
      "Epoch=13 Loss=0.039\n",
      "Epoch:13\n",
      "Epoch=14 Loss=0.028\n",
      "Epoch=14 Loss=0.044\n",
      "Epoch=14 Loss=0.044\n",
      "Epoch=14 Loss=0.030\n",
      "Epoch=14 Loss=0.020\n",
      "Epoch=14 Loss=0.011\n",
      "Epoch=14 Loss=0.039\n",
      "Epoch=14 Loss=0.088\n",
      "Epoch=14 Loss=0.039\n",
      "Epoch=14 Loss=0.014\n",
      "Epoch=14 Loss=0.033\n",
      "Epoch=14 Loss=0.068\n",
      "Epoch=14 Loss=0.021\n",
      "Epoch=14 Loss=0.049\n",
      "Epoch=14 Loss=0.015\n",
      "Epoch:14\n",
      "Epoch=15 Loss=0.050\n",
      "Epoch=15 Loss=0.024\n",
      "Epoch=15 Loss=0.015\n",
      "Epoch=15 Loss=0.013\n",
      "Epoch=15 Loss=0.051\n",
      "Epoch=15 Loss=0.026\n",
      "Epoch=15 Loss=0.019\n",
      "Epoch=15 Loss=0.013\n",
      "Epoch=15 Loss=0.027\n",
      "Epoch=15 Loss=0.071\n",
      "Epoch=15 Loss=0.020\n",
      "Epoch=15 Loss=0.080\n",
      "Epoch=15 Loss=0.045\n",
      "Epoch=15 Loss=0.035\n",
      "Epoch=15 Loss=0.072\n",
      "Epoch:15\n",
      "Epoch=16 Loss=0.011\n",
      "Epoch=16 Loss=0.026\n",
      "Epoch=16 Loss=0.029\n",
      "Epoch=16 Loss=0.015\n",
      "Epoch=16 Loss=0.020\n",
      "Epoch=16 Loss=0.023\n",
      "Epoch=16 Loss=0.081\n",
      "Epoch=16 Loss=0.039\n",
      "Epoch=16 Loss=0.033\n",
      "Epoch=16 Loss=0.021\n",
      "Epoch=16 Loss=0.036\n",
      "Epoch=16 Loss=0.020\n",
      "Epoch=16 Loss=0.013\n",
      "Epoch=16 Loss=0.017\n",
      "Epoch=16 Loss=0.022\n",
      "Epoch:16\n",
      "Epoch=17 Loss=0.022\n",
      "Epoch=17 Loss=0.019\n",
      "Epoch=17 Loss=0.021\n",
      "Epoch=17 Loss=0.037\n",
      "Epoch=17 Loss=0.030\n",
      "Epoch=17 Loss=0.033\n",
      "Epoch=17 Loss=0.032\n",
      "Epoch=17 Loss=0.038\n",
      "Epoch=17 Loss=0.019\n",
      "Epoch=17 Loss=0.041\n",
      "Epoch=17 Loss=0.017\n",
      "Epoch=17 Loss=0.053\n",
      "Epoch=17 Loss=0.030\n",
      "Epoch=17 Loss=0.012\n",
      "Epoch=17 Loss=0.026\n",
      "Epoch:17\n",
      "Epoch=18 Loss=0.029\n",
      "Epoch=18 Loss=0.034\n",
      "Epoch=18 Loss=0.036\n",
      "Epoch=18 Loss=0.012\n",
      "Epoch=18 Loss=0.036\n",
      "Epoch=18 Loss=0.039\n",
      "Epoch=18 Loss=0.015\n",
      "Epoch=18 Loss=0.026\n",
      "Epoch=18 Loss=0.059\n",
      "Epoch=18 Loss=0.017\n",
      "Epoch=18 Loss=0.062\n",
      "Epoch=18 Loss=0.022\n",
      "Epoch=18 Loss=0.029\n",
      "Epoch=18 Loss=0.010\n",
      "Epoch=18 Loss=0.032\n",
      "Epoch:18\n",
      "Epoch=19 Loss=0.018\n",
      "Epoch=19 Loss=0.037\n",
      "Epoch=19 Loss=0.018\n",
      "Epoch=19 Loss=0.015\n",
      "Epoch=19 Loss=0.016\n",
      "Epoch=19 Loss=0.020\n",
      "Epoch=19 Loss=0.035\n",
      "Epoch=19 Loss=0.031\n",
      "Epoch=19 Loss=0.035\n",
      "Epoch=19 Loss=0.013\n",
      "Epoch=19 Loss=0.019\n",
      "Epoch=19 Loss=0.011\n",
      "Epoch=19 Loss=0.009\n",
      "Epoch=19 Loss=0.014\n",
      "Epoch=19 Loss=0.037\n",
      "Epoch:19\n",
      "Epoch=20 Loss=0.011\n",
      "Epoch=20 Loss=0.020\n",
      "Epoch=20 Loss=0.022\n",
      "Epoch=20 Loss=0.036\n",
      "Epoch=20 Loss=0.046\n",
      "Epoch=20 Loss=0.027\n",
      "Epoch=20 Loss=0.032\n",
      "Epoch=20 Loss=0.014\n",
      "Epoch=20 Loss=0.026\n",
      "Epoch=20 Loss=0.033\n",
      "Epoch=20 Loss=0.020\n",
      "Epoch=20 Loss=0.028\n",
      "Epoch=20 Loss=0.042\n",
      "Epoch=20 Loss=0.025\n",
      "Epoch=20 Loss=0.016\n",
      "Epoch:20\n",
      "Epoch=21 Loss=0.010\n",
      "Epoch=21 Loss=0.026\n",
      "Epoch=21 Loss=0.021\n",
      "Epoch=21 Loss=0.028\n",
      "Epoch=21 Loss=0.031\n",
      "Epoch=21 Loss=0.012\n",
      "Epoch=21 Loss=0.031\n",
      "Epoch=21 Loss=0.024\n",
      "Epoch=21 Loss=0.042\n",
      "Epoch=21 Loss=0.023\n",
      "Epoch=21 Loss=0.026\n",
      "Epoch=21 Loss=0.010\n",
      "Epoch=21 Loss=0.043\n",
      "Epoch=21 Loss=0.032\n",
      "Epoch=21 Loss=0.022\n",
      "Epoch:21\n",
      "Epoch=22 Loss=0.046\n",
      "Epoch=22 Loss=0.021\n",
      "Epoch=22 Loss=0.028\n",
      "Epoch=22 Loss=0.020\n",
      "Epoch=22 Loss=0.019\n",
      "Epoch=22 Loss=0.021\n",
      "Epoch=22 Loss=0.023\n",
      "Epoch=22 Loss=0.039\n",
      "Epoch=22 Loss=0.052\n",
      "Epoch=22 Loss=0.079\n",
      "Epoch=22 Loss=0.012\n",
      "Epoch=22 Loss=0.030\n",
      "Epoch=22 Loss=0.030\n",
      "Epoch=22 Loss=0.024\n",
      "Epoch=22 Loss=0.036\n",
      "Epoch:22\n",
      "Epoch=23 Loss=0.010\n",
      "Epoch=23 Loss=0.021\n",
      "Epoch=23 Loss=0.020\n",
      "Epoch=23 Loss=0.010\n",
      "Epoch=23 Loss=0.015\n",
      "Epoch=23 Loss=0.011\n",
      "Epoch=23 Loss=0.018\n",
      "Epoch=23 Loss=0.050\n",
      "Epoch=23 Loss=0.014\n",
      "Epoch=23 Loss=0.061\n",
      "Epoch=23 Loss=0.010\n",
      "Epoch=23 Loss=0.019\n",
      "Epoch=23 Loss=0.026\n",
      "Epoch=23 Loss=0.048\n",
      "Epoch=23 Loss=0.030\n",
      "Epoch:23\n",
      "Epoch=24 Loss=0.010\n",
      "Epoch=24 Loss=0.024\n",
      "Epoch=24 Loss=0.044\n",
      "Epoch=24 Loss=0.014\n",
      "Epoch=24 Loss=0.023\n",
      "Epoch=24 Loss=0.037\n",
      "Epoch=24 Loss=0.016\n",
      "Epoch=24 Loss=0.023\n",
      "Epoch=24 Loss=0.026\n",
      "Epoch=24 Loss=0.062\n",
      "Epoch=24 Loss=0.046\n",
      "Epoch=24 Loss=0.042\n",
      "Epoch=24 Loss=0.022\n",
      "Epoch=24 Loss=0.032\n",
      "Epoch=24 Loss=0.012\n",
      "Epoch:24\n",
      "Epoch=25 Loss=0.035\n",
      "Epoch=25 Loss=0.013\n",
      "Epoch=25 Loss=0.012\n",
      "Epoch=25 Loss=0.014\n",
      "Epoch=25 Loss=0.010\n",
      "Epoch=25 Loss=0.054\n",
      "Epoch=25 Loss=0.030\n",
      "Epoch=25 Loss=0.026\n",
      "Epoch=25 Loss=0.035\n",
      "Epoch=25 Loss=0.017\n",
      "Epoch=25 Loss=0.027\n",
      "Epoch=25 Loss=0.027\n",
      "Epoch=25 Loss=0.049\n",
      "Epoch=25 Loss=0.021\n",
      "Epoch=25 Loss=0.019\n",
      "Epoch:25\n",
      "Epoch=26 Loss=0.030\n",
      "Epoch=26 Loss=0.014\n",
      "Epoch=26 Loss=0.029\n",
      "Epoch=26 Loss=0.054\n",
      "Epoch=26 Loss=0.015\n",
      "Epoch=26 Loss=0.077\n",
      "Epoch=26 Loss=0.021\n",
      "Epoch=26 Loss=0.059\n",
      "Epoch=26 Loss=0.039\n",
      "Epoch=26 Loss=0.034\n",
      "Epoch=26 Loss=0.043\n",
      "Epoch=26 Loss=0.016\n",
      "Epoch=26 Loss=0.026\n",
      "Epoch=26 Loss=0.028\n",
      "Epoch=26 Loss=0.019\n",
      "Epoch:26\n",
      "Epoch=27 Loss=0.015\n",
      "Epoch=27 Loss=0.040\n",
      "Epoch=27 Loss=0.039\n",
      "Epoch=27 Loss=0.020\n",
      "Epoch=27 Loss=0.017\n",
      "Epoch=27 Loss=0.023\n",
      "Epoch=27 Loss=0.024\n",
      "Epoch=27 Loss=0.077\n",
      "Epoch=27 Loss=0.016\n",
      "Epoch=27 Loss=0.034\n",
      "Epoch=27 Loss=0.027\n",
      "Epoch=27 Loss=0.033\n",
      "Epoch=27 Loss=0.016\n",
      "Epoch=27 Loss=0.043\n",
      "Epoch=27 Loss=0.019\n",
      "Epoch:27\n",
      "Epoch=28 Loss=0.032\n",
      "Epoch=28 Loss=0.069\n",
      "Epoch=28 Loss=0.019\n",
      "Epoch=28 Loss=0.042\n",
      "Epoch=28 Loss=0.017\n",
      "Epoch=28 Loss=0.025\n",
      "Epoch=28 Loss=0.022\n",
      "Epoch=28 Loss=0.019\n",
      "Epoch=28 Loss=0.035\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,tempeps \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(list_tempeps):\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dict_sourcedf[tempeps][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 99\u001b[0m         dict_temp \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m         dict_source[tempeps] \u001b[38;5;241m=\u001b[39m dict_temp\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m#create a list of eps / clips and shuffle\u001b[39;00m\n",
      "File \u001b[1;32me:\\Python310\\lib\\site-packages\\torch\\storage.py:370\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[1;34m(b)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;129m@_share_memory_lock_protected\u001b[39m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_share_filename_cpu_\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_share_filename_cpu_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_bytes\u001b[39m(b):\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(io\u001b[38;5;241m.\u001b[39mBytesIO(b))\n\u001b[0;32m    374\u001b[0m _StorageBase\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m _type  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Model Training 1 ##\n",
    "import pandas as pd\n",
    "import json\n",
    "import copy\n",
    "import csv\n",
    "import pickle\n",
    "import torchvision\n",
    "import itertools\n",
    "import torch\n",
    "import glob\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "#get number after # but before space afterwards\n",
    "\n",
    "#generate filepaths\n",
    "folderpath_clipinfo = ENV_FOLDER_DATA_PROC + 'clipinfo\\\\'\n",
    "os.makedirs(folderpath_clipinfo, exist_ok=True)\n",
    "folderpath_sourcedf = ENV_FOLDER_DATA_PROC + 'sourcedf\\\\'\n",
    "os.makedirs(folderpath_sourcedf, exist_ok=True)\n",
    "folderpath_targetdf = ENV_FOLDER_DATA_PROC + 'targetdf\\\\'\n",
    "folderpath_pratt = ENV_FOLDER_DATA_PROC + 'pratt\\\\' \n",
    "filepath_speakers = ENV_FOLDER_DATA_PROC + 'speakers.json'\n",
    "\n",
    "## get overlap between sourcedf files and targetdf files\n",
    "list_eps = []\n",
    "\n",
    "#note - source is actually a dict of dict of tensors\n",
    "dict_sourcedf = {}\n",
    "list_sourcedf_eps = []\n",
    "for path_pickle in glob.glob(folderpath_sourcedf + '*.pickle'):\n",
    "    dict_temp = {}\n",
    "    dict_temp['path'] = path_pickle\n",
    "    str_basenm = os.path.basename(path_pickle)\n",
    "    dict_temp['basenm'] = str_basenm\n",
    "    dict_temp['str_epnum'] = str_basenm.split('.')[0]\n",
    "    int_epnum = int(dict_temp['str_epnum'])\n",
    "    dict_temp['int_epnum'] = int_epnum\n",
    "    list_sourcedf_eps.append(int_epnum)\n",
    "    dict_sourcedf[int_epnum] = dict_temp\n",
    "\n",
    "#note - target is actually a df\n",
    "dict_targetdf = {}\n",
    "list_targetdf_eps = []\n",
    "for path_pickle in glob.glob(folderpath_targetdf + '*.pickle'):\n",
    "    dict_temp = {}\n",
    "    dict_temp['path'] = path_pickle\n",
    "    str_basenm = os.path.basename(path_pickle)\n",
    "    dict_temp['basenm'] = str_basenm\n",
    "    dict_temp['str_epnum'] = str_basenm.split('.')[0]\n",
    "    int_epnum = int(dict_temp['str_epnum'])\n",
    "    dict_temp['int_epnum'] = int_epnum\n",
    "    list_targetdf_eps.append(int_epnum)\n",
    "    dict_targetdf[int_epnum] = dict_temp\n",
    "\n",
    "#populate matches\n",
    "for src_ep in list_sourcedf_eps:\n",
    "    if src_ep in list_targetdf_eps:\n",
    "        list_eps.append(src_ep)\n",
    "\n",
    "#40 data elements\n",
    "list_datacols = []\n",
    "list_datacols.append('m')\n",
    "for i in range(40):\n",
    "    list_datacols.append('d' + str(i))\n",
    "\n",
    "#define model pieces\n",
    "NUM_EPOCHS = 100\n",
    "TRAINING_TYPE = 'p'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#transform=torchvision.transforms.Normalize( mean=(255*0.5), std=(255*0.5) )\n",
    "optimizer = torch.optim.Adam(a.parameters(), lr=0.001, betas=(0.8, 0.999))\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "\n",
    "\n",
    "##Epoch Loop\n",
    "for e in range(NUM_EPOCHS):\n",
    "    print('Epoch:' + str(e))\n",
    "    #make a copy of the episode list to pop out 2 at a time\n",
    "    list_epocheps = copy.deepcopy(list_eps)\n",
    "    random.shuffle(list_epocheps)\n",
    "    while len(list_epocheps) > 0:\n",
    "        #load two or 3 episodes into memory at a time\n",
    "        list_tempeps = []\n",
    "        for i in range(3):\n",
    "            if len(list_epocheps) > 0:\n",
    "                list_tempeps.append(list_epocheps.pop())\n",
    "        #load pratt files into memory\n",
    "        dict_target = {}\n",
    "        for i,tempeps in enumerate(list_tempeps):\n",
    "            with open(dict_targetdf[tempeps]['path'], 'rb') as file:\n",
    "                dict_target[tempeps] =  pickle.load(file)\n",
    "                    \n",
    "        #load video files into memory\n",
    "        dict_source = {}\n",
    "        for i,tempeps in enumerate(list_tempeps):\n",
    "            with open(dict_sourcedf[tempeps]['path'], 'rb') as file:\n",
    "                dict_temp = pickle.load(file)\n",
    "                dict_source[tempeps] = dict_temp\n",
    "\n",
    "        #create a list of eps / clips and shuffle\n",
    "        listtup_epseg = []\n",
    "        for key,val in dict_source.items():\n",
    "            for key2,val2 in val.items():\n",
    "                tup_epseg = [key,key2]\n",
    "                listtup_epseg.append( tup_epseg)\n",
    "        random.shuffle(listtup_epseg)\n",
    "\n",
    "        #loop for data elements\n",
    "        for tup_epseg in listtup_epseg:\n",
    "            int_epnum = tup_epseg[0]\n",
    "            int_segnum = tup_epseg[1]\n",
    "            #feed values into the predict / loss / optimize cycle\n",
    "            inputs = None\n",
    "            labels = None\n",
    "            if int_epnum not in dict_source.keys():\n",
    "                continue\n",
    "            if int_segnum not in dict_source[int_epnum].keys():\n",
    "                continue\n",
    "            inputs = dict_source[int_epnum][int_segnum]\n",
    "            #pad inputs\n",
    "            for x in range(40 - len(inputs)):\n",
    "                inputs.append( torch.empty((1,360,640), dtype=torch.int8) )\n",
    "            inputs = torch.stack(inputs[:40], 0)\n",
    "            #transform inputs\n",
    "            #print(inputs.size())\n",
    "            #torch.Size([40, 1, 360, 640])\n",
    "            inputs = inputs.to(torch.float).movedim(0,1).unsqueeze(0) / 255.0\n",
    "            #print(inputs.size())\n",
    "            \n",
    "\n",
    "            #check if labels exist\n",
    "            label_df = dict_target[int_epnum].query('seg==' + str(int_segnum) + ' & type==\"' + TRAINING_TYPE + '\"' )\n",
    "            if len(label_df) == 0:\n",
    "                #print('No labels for ep:' + str(int_epnum) + ' seg:' + str(int_segnum))\n",
    "                continue\n",
    "            labels = torch.squeeze(torch.tensor(label_df[list_datacols].fillna(0).values).to(torch.float))\n",
    "            #normalize labels \n",
    "            if TRAINING_TYPE == 'p':\n",
    "                labels = labels / 600.0\n",
    "            elif TRAINING_TYPE == 'i':\n",
    "                labels = labels / 100.0\n",
    "            elif TRAINING_TYPE == 's':\n",
    "                labels = labels / 2\n",
    "            elif TRAINING_TYPE == 'j':\n",
    "                labels = labels\n",
    "            elif TRAINING_TYPE == 'h':\n",
    "                labels = (labels + 40) / 100\n",
    "            \n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = a(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        print(f'Epoch={e + 1} Loss={loss.item():.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #define a function that, given a targetdf value, look up the source - if both exists, use the data to train the model\n",
    "\n",
    "#end loop through data\n",
    "#33 minutes per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model down for future use / training\n",
    "torch.save(a.state_dict(), ENV_FOLDER_DATA_PROC + 'charts\\\\' + \"JWPitchModv03.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have some metric to show "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
